{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import maup # mggg's library for proration, see documentation here: https://github.com/mggg/maup\n",
    "import pandas as pd # standard python data library\n",
    "import geopandas as gp # the geo-version of pandas\n",
    "import numpy as np \n",
    "import os\n",
    "import fiona\n",
    "from statistics import mean, median\n",
    "from pandas import read_csv\n",
    "gp.io.file.fiona.drvsupport.supported_drivers['KML'] = 'rw' #To load KML files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load VEST File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pct_std County Precnct  G18USSRSCO  G18USSDNEL  G18GOVRDES  G18GOVDGIL  \\\n",
      "0  ALA0001    ALA      01         532         372         544         357   \n",
      "1  ALA0002    ALA      02         717         662         739         622   \n",
      "2  ALA0003    ALA      03        1541        1192        1592        1123   \n",
      "3  ALA0004    ALA      04        1320         767        1372         688   \n",
      "4  ALA0005    ALA      05         433        1545         438        1525   \n",
      "\n",
      "   G18GOVORIC  G18GOVONPA  G18ATGRMOO  ...  G18A09NO  G18A10YES  G18A10NO  \\\n",
      "0           2           7         563  ...       358        500       367   \n",
      "1          12          13         762  ...       552        743       563   \n",
      "2          13          16        1646  ...      1021       1476      1096   \n",
      "3           8          17        1408  ...       897       1169       811   \n",
      "4           7          11         483  ...       384        631      1178   \n",
      "\n",
      "   G18A11YES  G18A11NO  G18A12YES  G18A12NO  G18A13YES  G18A13NO  \\\n",
      "0        434       421        613       254        476       414   \n",
      "1        667       619        879       449        748       600   \n",
      "2       1348      1161       1884       730       1640      1013   \n",
      "3       1068       893       1392       618       1081       962   \n",
      "4        906       888       1181       671       1554       383   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((-82.24245 29.85246, -82.24106 29.852...  \n",
      "1  POLYGON ((-82.41775 29.92248, -82.41711 29.922...  \n",
      "2  POLYGON ((-82.53335 29.84801, -82.52809 29.838...  \n",
      "3  POLYGON ((-82.55700 29.65461, -82.55638 29.654...  \n",
      "4  POLYGON ((-82.34441 29.66672, -82.34334 29.666...  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "PAL00NP    67\n",
      "SAR0335     1\n",
      "JEF0014     1\n",
      "PAL6176     1\n",
      "ORA0403     1\n",
      "           ..\n",
      "CIT0407     1\n",
      "SAR0119     1\n",
      "DAD0529     1\n",
      "ALA0052     1\n",
      "OSC0522     1\n",
      "Name: Pct_std, Length: 6007, dtype: int64\n",
      "(5, 43)\n",
      "      Pct_std County Precnct  G18USSRSCO  G18USSDNEL  G18GOVRDES  G18GOVDGIL  \\\n",
      "5895  UNI001A    UNI   1A+1B         608         213         654         169   \n",
      "5896  UNI002A    UNI   2A+2B         575         181         604         148   \n",
      "5897  UNI003A    UNI   3A+3B         817         220         849         178   \n",
      "5899  UNI004A    UNI   4A+4C         340         145         354         133   \n",
      "5901  UNI005A    UNI   5A+5C         186         105         197          90   \n",
      "\n",
      "      G18GOVORIC  G18GOVONPA  G18ATGRMOO  ...  G18A10NO  G18A11YES  G18A11NO  \\\n",
      "5895           1           6         650  ...       243        426       343   \n",
      "5896           6           5         604  ...       201        380       311   \n",
      "5897           6           5         851  ...       273        510       455   \n",
      "5899           2           3         358  ...       152        255       210   \n",
      "5901           1           2         203  ...        97        142       129   \n",
      "\n",
      "      G18A12YES  G18A12NO  G18A13YES  G18A13NO  \\\n",
      "5895        528       258        391       420   \n",
      "5896        524       182        303       430   \n",
      "5897        681       306        454       561   \n",
      "5899        327       143        233       250   \n",
      "5901        188        90        141       141   \n",
      "\n",
      "                                               geometry     check  confirm  \n",
      "5895  POLYGON ((-82.28243 30.14178, -82.28086 30.042...  UNI1A+1B    False  \n",
      "5896  POLYGON ((-82.14264 30.14282, -82.14273 30.142...  UNI2A+2B    False  \n",
      "5897  POLYGON ((-82.40786 29.99558, -82.40737 29.986...  UNI3A+3B    False  \n",
      "5899  POLYGON ((-82.40851 30.05273, -82.40843 30.052...  UNI4A+4C    False  \n",
      "5901  POLYGON ((-82.33347 30.10702, -82.33351 30.039...  UNI5A+5C    False  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "#Load the file\n",
    "vest_fl = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/fl_2018/fl_2018.shp\")\n",
    "\n",
    "#Take look at the file, looks like \"Pct_std\" is the unique identifier column\n",
    "print(vest_fl.head())\n",
    "\n",
    "#Look whether all the values are unique\n",
    "#All the values seem to be unique, except for \"PAL00NP\" - which occurs 67 times\n",
    "print(vest_fl[\"Pct_std\"].value_counts())\n",
    "\n",
    "#Pattern for unique identifier seems to be county + at least four digit \"Precnct\"\n",
    "#Check if there are any that don't match this (might be helpful to know)\n",
    "vest_fl[\"check\"]=vest_fl[\"County\"]+vest_fl[\"Precnct\"].astype(str).str.zfill(4)\n",
    "vest_fl[\"confirm\"]=vest_fl[\"Pct_std\"]==vest_fl[\"check\"]\n",
    "\n",
    "#It looks like there are 5 rows that don't match this pattern, keep this in mind for later\n",
    "print(vest_fl[vest_fl[\"confirm\"]==False].shape)\n",
    "print(vest_fl[vest_fl[\"confirm\"]==False])\n",
    "\n",
    "#Grab the CRS, as I will need this for later\n",
    "#vest_fl[\"geometry\"]=vest_fl.buffer(0)\n",
    "vest_proj = vest_fl.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pct_std', 'County', 'Precnct', 'G18USSRSCO', 'G18USSDNEL',\n",
      "       'G18GOVRDES', 'G18GOVDGIL', 'G18GOVORIC', 'G18GOVONPA', 'G18ATGRMOO',\n",
      "       'G18ATGDSHA', 'G18ATGOSIS', 'G18CFORPAT', 'G18CFODRIN', 'G18AGRRCAL',\n",
      "       'G18AGRDFRI', 'G18A01YES', 'G18A01NO', 'G18A02YES', 'G18A02NO',\n",
      "       'G18A03YES', 'G18A03NO', 'G18A04YES', 'G18A04NO', 'G18A05YES',\n",
      "       'G18A05NO', 'G18A06YES', 'G18A06NO', 'G18A07YES', 'G18A07NO',\n",
      "       'G18A09YES', 'G18A09NO', 'G18A10YES', 'G18A10NO', 'G18A11YES',\n",
      "       'G18A11NO', 'G18A12YES', 'G18A12NO', 'G18A13YES', 'G18A13NO',\n",
      "       'geometry', 'check', 'confirm'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Look at the VEST unique identifier column\n",
    "print(vest_fl.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Precinct-level Elections Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This Data is from the FL department of state, and can only be downloaded county by county\n",
    "all_files = os.listdir(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/precinctlevelelectionresults2018gen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that all files have the same number of columns\n",
    "for i in all_files:\n",
    "    ref = \"./precinctlevelelectionresults2018gen/\"\n",
    "    file_ref = ref+i\n",
    "    file_prev = pd.read_csv(file_ref,sep=\"\\t\",engine='python',index_col=None, header=None)\n",
    "    print(file_prev.shape)\n",
    "    \n",
    "#All the files have 19 columns, so they should be good to combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(743093, 19)\n"
     ]
    }
   ],
   "source": [
    "#Create a dataframe with the txt files\n",
    "li = []\n",
    "for i in all_files:\n",
    "    ref = \"./precinctlevelelectionresults2018gen/\"\n",
    "    file_ref = ref+i\n",
    "    file_prev = pd.read_csv(file_ref,sep=\"\\t\",engine='python',index_col=None, header=None)\n",
    "    li.append(file_prev)\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "print(frame.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to data definitions and field codes  \n",
    "https://fldoswebumbracoprod.blob.core.windows.net/media/694099/precinct-level-results-data-definition-field-codes.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0       1      2           3                      4  5              6   \\\n",
      "0  HOL  Holmes  10481  11/06/2018  2018 General Election  1  Ponce de Leon   \n",
      "1  HOL  Holmes  10481  11/06/2018  2018 General Election  1  Ponce de Leon   \n",
      "2  HOL  Holmes  10481  11/06/2018  2018 General Election  1  Ponce de Leon   \n",
      "3  HOL  Holmes  10481  11/06/2018  2018 General Election  1  Ponce de Leon   \n",
      "4  HOL  Holmes  10481  11/06/2018  2018 General Election  1  Ponce de Leon   \n",
      "\n",
      "     7   8   9   10                     11 12      13            14   15  \\\n",
      "0  1152   0   0   0  United States Senator     120000    Rick Scott  REP   \n",
      "1  1152   0   0   0  United States Senator     120000   Bill Nelson  DEM   \n",
      "2  1152   0   0   0  United States Senator     120000  WriteinVotes        \n",
      "3  1152   0   0   0  United States Senator     120000     OverVotes        \n",
      "4  1152   0   0   0  United States Senator     120000    UnderVotes        \n",
      "\n",
      "          16     17   18  \n",
      "0  103093132  71039  601  \n",
      "1  113049868  70482   97  \n",
      "2          0    900    3  \n",
      "3          0    901    0  \n",
      "4          0    902    7  \n"
     ]
    }
   ],
   "source": [
    "print(frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter down to the relevant races\n",
    "office_List = ['United States Senator','Governor','Attorney General','Chief Financial Officer','Commissioner of Agriculture','Amendment No. 1: Increased Homestead Property Tax Exemption','Amendment No. 2: Limitations on Property Tax Assessments','Amendment No. 3: Voter Control of Gambling in Florida','Amendment No. 4: Voting Restoration Amendment','Amendment No. 5: Supermajority Vote Required to Impose, Authorize, or Raise State Taxes or Fees','Amendment No. 6: Rights of Crime Victims; Judges','Amendment No. 7: First Responder and Military Member Survivor Benefits; Public Colleges and Universities','Amendment No. 9: Prohibits Offshore Oil and Gas Drilling; Prohibits Vaping in Enclosed Indoor Workplaces','Amendment No. 10: State and Local Government Structure and Operation','Amendment No. 11: Property Rights; Removal of Obsolete Provision; Criminal Statutes','Amendment No. 12: Lobbying and Abuse of Office by Public Officers','Amendment No. 13: Ends Dog Racing']\n",
    "filtered_frame=frame[frame[11].isin(office_List)]\n",
    "\n",
    "#Filter out unused columns\n",
    "filtered_frame = filtered_frame.drop(columns=[1,2,3,4,8,9,10,12,13],axis=1)\n",
    "\n",
    "#Filter out Senator WriteinVotes and OverVotes and UnderVotes\n",
    "no_count = ['WriteinVotes','OverVotes','UnderVotes']\n",
    "filtered_frame = filtered_frame[~filtered_frame[14].isin(no_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From taking a look at the VEST file, this is the way to create the unique ID \n",
    "\n",
    "#Make the precinct column at least 4 digits\n",
    "filtered_frame[5]=filtered_frame[5].astype(str)\n",
    "filtered_frame[\"modified_pre\"]=filtered_frame[5].str.zfill(4)\n",
    "\n",
    "#Make a column with the 3 letter county code and the precincts\n",
    "filtered_frame[\"Pct_std\"]=filtered_frame[0]+filtered_frame[\"modified_pre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivot the data so that each row has all the results from that precinct\n",
    "pivoted_2018 = pd.pivot_table(filtered_frame, values=[18], index=[\"Pct_std\"],columns=[11,14],aggfunc=sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up index\n",
    "pivoted_2018 = pivoted_2018.reset_index()\n",
    "pd.set_option('display.max_columns', None)\n",
    "#display(pivoted_2018)\n",
    "\n",
    "#Rename the columns\n",
    "pivoted_2018.columns=['Pct_std','G18A10NO','G18A10YES','G18A11NO','G18A11YES','G18A12NO','G18A12YES','G18A13NO','G18A13YES','G18A01NO','G18A01YES',\n",
    "                      'G18A02NO','G18A02YES', 'G18A03NO','G18A03YES','G18A04NO','G18A04YES','G18A05NO','G18A05YES',\n",
    "                      'G18A06NO', 'G18A06YES','G18A07NO', 'G18A07YES','G18A09NO','G18A09YES',\n",
    "                      'G18ATGRMOO', 'G18ATGOSIS','G18ATGDSHA','G18CFODRIN','G18CFORPAT', 'G18AGRRCAL','G18AGRDFRI', \n",
    "                       'G18GOVRDES','G18GOV_to_add1','G18GOV_to_add2','G18GOVDGIL','G18GOVORIC','G18GOV_to_add3','G18USSDNEL','G18USSRSCO']\n",
    "\n",
    "#Fix governors results (they count all the no party candidates together)\n",
    "pivoted_2018['G18GOVONPA']=pivoted_2018['G18GOV_to_add1']+pivoted_2018['G18GOV_to_add2']+pivoted_2018['G18GOV_to_add3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pct_std  G18A10NO  G18A10YES  G18A11NO  G18A11YES  G18A12NO  G18A12YES  \\\n",
      "0  ALA0001     367.0      500.0     421.0      434.0     254.0      613.0   \n",
      "1  ALA0002     563.0      743.0     619.0      667.0     449.0      879.0   \n",
      "2  ALA0003    1096.0     1476.0    1161.0     1348.0     730.0     1884.0   \n",
      "3  ALA0004     811.0     1169.0     893.0     1068.0     618.0     1392.0   \n",
      "4  ALA0005    1178.0      631.0     888.0      906.0     671.0     1181.0   \n",
      "\n",
      "   G18A13NO  G18A13YES  G18A01NO  G18A01YES  G18A02NO  G18A02YES  G18A03NO  \\\n",
      "0     414.0      476.0     420.0      464.0     357.0      512.0     236.0   \n",
      "1     600.0      748.0     651.0      702.0     571.0      760.0     346.0   \n",
      "2    1013.0     1640.0    1141.0     1525.0     988.0     1625.0     731.0   \n",
      "3     962.0     1081.0     799.0     1244.0     643.0     1382.0     635.0   \n",
      "4     383.0     1554.0    1313.0      562.0    1138.0      708.0     505.0   \n",
      "\n",
      "   G18A03YES  G18A04NO  G18A04YES  G18A05NO  G18A05YES  G18A06NO  G18A06YES  \\\n",
      "0      659.0     375.0      526.0     301.0      576.0     386.0      502.0   \n",
      "1     1015.0     551.0      816.0     531.0      806.0     634.0      708.0   \n",
      "2     1939.0    1134.0     1539.0     941.0     1692.0    1255.0     1383.0   \n",
      "3     1416.0     975.0     1077.0     627.0     1403.0     908.0     1115.0   \n",
      "4     1405.0     313.0     1642.0    1199.0      681.0    1251.0      616.0   \n",
      "\n",
      "   G18A07NO  G18A07YES  G18A09NO  G18A09YES  G18ATGRMOO  G18ATGOSIS  \\\n",
      "0     387.0      490.0     358.0      529.0       563.0        17.0   \n",
      "1     600.0      747.0     552.0      799.0       762.0        32.0   \n",
      "2    1072.0     1557.0    1021.0     1616.0      1646.0        42.0   \n",
      "3     813.0     1216.0     897.0     1124.0      1408.0        24.0   \n",
      "4    1117.0      758.0     384.0     1543.0       483.0        38.0   \n",
      "\n",
      "   G18ATGDSHA  G18CFODRIN  G18CFORPAT  G18AGRRCAL  G18AGRDFRI  G18GOVRDES  \\\n",
      "0       323.0       348.0       539.0       545.0       347.0       544.0   \n",
      "1       584.0       617.0       740.0       740.0       622.0       739.0   \n",
      "2      1022.0      1102.0      1563.0      1592.0      1100.0      1592.0   \n",
      "3       629.0       677.0      1358.0      1356.0       687.0      1372.0   \n",
      "4      1412.0      1397.0       509.0       448.0      1471.0       438.0   \n",
      "\n",
      "   G18GOV_to_add1  G18GOV_to_add2  G18GOVDGIL  G18GOVORIC  G18GOV_to_add3  \\\n",
      "0             3.0             4.0       357.0         2.0             0.0   \n",
      "1             1.0             4.0       622.0        12.0             8.0   \n",
      "2             4.0             8.0      1123.0        13.0             4.0   \n",
      "3             6.0             7.0       688.0         8.0             4.0   \n",
      "4             2.0             5.0      1525.0         7.0             4.0   \n",
      "\n",
      "   G18USSDNEL  G18USSRSCO  G18GOVONPA County  \n",
      "0       372.0       532.0         7.0    ALA  \n",
      "1       662.0       717.0        13.0    ALA  \n",
      "2      1192.0      1541.0        16.0    ALA  \n",
      "3       767.0      1320.0        17.0    ALA  \n",
      "4      1545.0       433.0        11.0    ALA  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5999, 42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recreate the county code\n",
    "pivoted_2018[\"County\"]=pivoted_2018[\"Pct_std\"].str[0:3]\n",
    "\n",
    "#Check how it looks\n",
    "print(pivoted_2018.head())\n",
    "pivoted_2018.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all there are 5,999 rows in the precinct election results dataframe. The next step is to merge these precincts with the shapefiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Shapefiles**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation mentions 4 different sources for the shapefiles:\n",
    "\n",
    "1) Florida department of state (16 counties)  \n",
    "2) 2016 VEST shapefile (17 counties)  \n",
    "3) U.S. Census Bureau's 2020 Redistricting Data Program Phase 2 release (18 counties)  \n",
    "4) Counties themselves (14 counties)  \n",
    "\n",
    "67 total counties in FL, sources for 65 listed here.  \n",
    "\n",
    "2 remaining counties are:  Columbia, Duval  \n",
    "\n",
    "From an email conversation w/ Brian Amos (brianamos@gmail.com) on 01/13/21, I learned that:  \n",
    "    \"Columbia and Duval were sent from their respective SOE offices\"  \n",
    "    \"FL DOS shapefiles were a records request\"  \n",
    "    \n",
    "So, there are actually 16 counties where shapefiles were received from the Counties themselves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resource: county names and three letter codes sheet**\n",
    "  \n",
    "['HOL' 'LEV' 'STL' 'HAR' 'CAL' 'ALA' 'HER' 'WAK' 'MON' 'POL' 'OSC' 'JAC'\n",
    " 'WAL' 'DES' 'PAS' 'DIX' 'JEF' 'MRN' 'GIL' 'TAY' 'GAD' 'SUW' 'STJ' 'SEM'\n",
    " 'BAK' 'SAN' 'OKA' 'PAL' 'SAR' 'BRO' 'BRE' 'CIT' 'GUL' 'HIG' 'MAN' 'IND'\n",
    " 'MAD' 'PIN' 'LEO' 'LEE' 'NAS' 'FLA' 'OKE' 'CLM' 'LAK' 'UNI' 'BRA' 'DUV'\n",
    " 'LAF' 'BAY' 'FRA' 'CLA' 'ORA' 'SUM' 'LIB' 'HAM' 'GLA' 'PUT' 'CLL' 'HEN'\n",
    " 'MRT' 'DAD' 'HIL' 'VOL' 'CHA' 'ESC' 'WAS']  \n",
    " \n",
    "['Holmes' 'Levy' 'St. Lucie' 'Hardee' 'Calhoun' 'Alachua' 'Hernando'\n",
    " 'Wakulla' 'Monroe' 'Polk' 'Osceola' 'Jackson' 'Walton' 'Desoto' 'Pasco'\n",
    " 'Dixie' 'Jefferson' 'Marion' 'Gilchrist' 'Taylor' 'Gadsden' 'Suwannee'\n",
    " 'St. Johns' 'Seminole' 'Baker' 'Santa Rosa' 'Okaloosa' 'Palm Beach'\n",
    " 'Sarasota' 'Broward' 'Brevard' 'Citrus' 'Gulf' 'Highlands' 'Manatee'\n",
    " 'Indian River' 'Madison' 'Pinellas' 'Leon' 'Lee' 'Nassau' 'Flagler'\n",
    " 'Okeechobee' 'Columbia' 'Lake' 'Union' 'Bradford' 'Duval' 'Lafayette'\n",
    " 'Bay' 'Franklin' 'Clay' 'Orange' 'Sumter' 'Liberty' 'Hamilton' 'Glades'\n",
    " 'Putnam' 'Collier' 'Hendry' 'Martin' 'Miami-Dade' 'Hillsborough'\n",
    " 'Volusia' 'Charlotte' 'Escambia' 'Washington']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Florida Department of State (16 counties)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quote from the README\n",
    "\n",
    "> \"Alachua, Baker, Bay, Bradford, Brevard, Calhoun, Citrus, Clay, Dixie, Escambia, Hardee, Hendry, Hernando, Indian River, Lafayette and Sarasota come from the Department of State.\"\n",
    "\n",
    "Note: As mentioned above, these were received by VEST via a records request. Peter called an employee (850-688-2433) of the DOS a few times, the last time being January 15th, 2021 to ask about a precinct shapefile. The FL DOS is sending a CD over with all of its precinct related archive data. At the time of writing, we have not yet recieved the files from the FL DOS.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. VEST '16 (17 counties)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quote from the README:\n",
    "\n",
    "> \"Broward, Desoto, Gadsden, Gilchrist, Gulf, Manatee, Marion, Martin, Monroe, Nassau, Pinellas, Polk, Putnam, Santa Rosa, St. Johns, St. Lucie, and Union are unchanged from the 2016 VEST shapefile.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest_16 = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/fl_2016/fl_2016.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pct county countypct  G16PRERTru  G16PREDCli  G16PRELJon  G16PRECCas  \\\n",
      "0  001    DAD    DAD001         277         195           4           0   \n",
      "1  010    DAD    DAD010          20          16           0           0   \n",
      "2  100    DAD    DAD100         641        2893          66          17   \n",
      "3  101    DAD    DAD101         679        1096          34           0   \n",
      "4  102    DAD    DAD102        1100        1596          29           1   \n",
      "\n",
      "   G16PREGSte  G16PREIDeL  G16PREoth  G16USSRRub  G16USSDMur  G16USSLSta  \\\n",
      "0           2           0          5         337         133           3   \n",
      "1           0           0          0          30           6           0   \n",
      "2          41          16         24         897        2434          50   \n",
      "3           7           0         18         845         947          14   \n",
      "4           4           2         22        1399        1274          16   \n",
      "\n",
      "   G16USSOth                                           geometry  \n",
      "0          5  POLYGON Z ((943790.734 591023.581 0.000, 94364...  \n",
      "1          0  POLYGON Z ((942137.421 562243.019 0.000, 94093...  \n",
      "2         99  POLYGON Z ((873353.097 533771.394 0.000, 87420...  \n",
      "3         17  POLYGON Z ((936263.331 593379.375 0.000, 93560...  \n",
      "4         32  POLYGON Z ((940693.858 597222.143 0.000, 94069...  \n",
      "['DAD' 'VOL' 'UNI' 'SAR' 'SAN' 'PUT' 'POL' 'PIN' 'PAL' 'OSC' 'ORA' 'MRN'\n",
      " 'LEO' 'LEE' 'LAK' 'HIL' 'HIG' 'DES' 'CAL' 'BRE' 'ALA' 'BAK' 'BAY' 'BRA'\n",
      " 'BRO' 'CIT' 'CLA' 'CLL' 'DIX' 'DUV' 'ESC' 'FLA' 'FRA' 'GAD' 'GIL' 'GLA'\n",
      " 'GUL' 'HAM' 'HAR' 'IND' 'LAF' 'LIB' 'MAN' 'MRT' 'MON' 'NAS' 'OKA' 'OKE'\n",
      " 'PAS' 'SEM' 'STJ' 'STL' 'SUM' 'SUW' 'TAY' 'WAK' 'WAS' 'JEF' 'CLM' 'CHA'\n",
      " 'JAC' 'HEN' 'LEV' 'HER' 'MAD' 'WAL' 'HOL']\n",
      "      pct county countypct                                           geometry  \\\n",
      "908  001A    UNI    UNI 1A  POLYGON Z ((234533.388 2067718.870 0.000, 2345...   \n",
      "909  001B    UNI    UNI 1B  POLYGON Z ((250790.618 2113766.930 0.000, 2508...   \n",
      "910  002A    UNI   UNI  2A  POLYGON Z ((267244.669 2086000.346 0.000, 2662...   \n",
      "911  002B    UNI   UNI  2B  POLYGON Z ((255460.267 2067684.326 0.000, 2555...   \n",
      "912  003A    UNI    UNI 3A  MULTIPOLYGON Z (((205086.233 2033920.141 0.000...   \n",
      "\n",
      "     Pct_std  \n",
      "908  UNI001A  \n",
      "909  UNI001B  \n",
      "910  UNI002A  \n",
      "911  UNI002B  \n",
      "912  UNI003A  \n"
     ]
    }
   ],
   "source": [
    "#Take a look at the file\n",
    "print(vest_16.head())\n",
    "\n",
    "#Look at the unique county\n",
    "print(vest_16[\"county\"].unique())\n",
    "\n",
    "#Make a list of relevant counties to pull\n",
    "vest_2016_counties = ['BRO','DES','GAD','GIL','GUL','MAN','MRN','MRT','MON','NAS','PIN','POL','PUT',\n",
    "                     'SAN','STJ','STL','UNI']\n",
    "\n",
    "#Filter down to the relevant counties\n",
    "shapefiles_vest_16=vest_16[vest_16['county'].isin(vest_2016_counties)]\n",
    "\n",
    "#Pull the relevant columns\n",
    "shapefiles_vest_16=shapefiles_vest_16[['pct','county','countypct','geometry']]\n",
    "\n",
    "#Modify the pct column so that it contains at least 4 characters\n",
    "shapefiles_vest_16[\"pct\"]=shapefiles_vest_16[\"pct\"].astype(str).str.zfill(4)\n",
    "\n",
    "#Create a new unique identifier column\n",
    "shapefiles_vest_16[\"Pct_std\"]=shapefiles_vest_16[\"county\"]+shapefiles_vest_16[\"pct\"]\n",
    "\n",
    "#Take a look at the new, modified file\n",
    "print(shapefiles_vest_16.head())\n",
    "\n",
    "#Filter the columns to only include 'Pct_std' and geometry\n",
    "shapefiles_vest_16=shapefiles_vest_16[[\"Pct_std\",\"geometry\"]]\n",
    "\n",
    "#Edit the CRS, so it matches that of the VEST file\n",
    "shapefiles_vest_16 = shapefiles_vest_16.to_crs(vest_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pct_std  G18A10NO  G18A10YES  G18A11NO  G18A11YES  G18A12NO  G18A12YES  \\\n",
      "304  BROA001    1204.0     1366.0     922.0     1607.0     341.0     2262.0   \n",
      "305  BROA002     288.0      422.0     248.0      451.0     120.0      585.0   \n",
      "306  BROA003     341.0      649.0     326.0      641.0     167.0      824.0   \n",
      "307  BROA004     300.0      464.0     290.0      473.0     168.0      618.0   \n",
      "308  BROA005     342.0      570.0     321.0      583.0     114.0      824.0   \n",
      "\n",
      "     G18A13NO  G18A13YES  G18A01NO  G18A01YES  G18A02NO  G18A02YES  G18A03NO  \\\n",
      "304     787.0     1855.0     837.0     1755.0     564.0     1989.0     887.0   \n",
      "305     174.0      550.0     277.0      417.0     189.0      506.0     219.0   \n",
      "306     222.0      785.0     439.0      531.0     279.0      674.0     263.0   \n",
      "307     184.0      612.0     352.0      423.0     255.0      503.0     236.0   \n",
      "308     239.0      725.0     299.0      622.0     228.0      679.0     259.0   \n",
      "\n",
      "     G18A03YES  G18A04NO  G18A04YES  G18A05NO  G18A05YES  G18A06NO  G18A06YES  \\\n",
      "304     1792.0    1177.0     1505.0     844.0     1815.0     972.0     1625.0   \n",
      "305      515.0     247.0      483.0     240.0      481.0     263.0      447.0   \n",
      "306      798.0     340.0      698.0     353.0      667.0     324.0      670.0   \n",
      "307      572.0     271.0      539.0     278.0      524.0     270.0      507.0   \n",
      "308      724.0     397.0      577.0     293.0      671.0     335.0      615.0   \n",
      "\n",
      "     G18A07NO  G18A07YES  G18A09NO  G18A09YES  G18ATGRMOO  G18ATGOSIS  \\\n",
      "304     947.0     1647.0     630.0     1973.0      1575.0        45.0   \n",
      "305     223.0      482.0     159.0      551.0       313.0        13.0   \n",
      "306     297.0      673.0     227.0      749.0       524.0        12.0   \n",
      "307     263.0      501.0     176.0      596.0       345.0        11.0   \n",
      "308     304.0      639.0     226.0      723.0       555.0        12.0   \n",
      "\n",
      "     G18ATGDSHA  G18CFODRIN  G18CFORPAT  G18AGRRCAL  G18AGRDFRI  G18GOVRDES  \\\n",
      "304      1094.0      1091.0      1601.0      1541.0      1159.0      1615.0   \n",
      "305       430.0       433.0       318.0       311.0       442.0       311.0   \n",
      "306       629.0       636.0       519.0       521.0       628.0       552.0   \n",
      "307       496.0       503.0       346.0       342.0       504.0       353.0   \n",
      "308       454.0       454.0       557.0       546.0       468.0       566.0   \n",
      "\n",
      "     G18GOV_to_add1  G18GOV_to_add2  G18GOVDGIL  G18GOVORIC  G18GOV_to_add3  \\\n",
      "304             4.0             8.0      1118.0         7.0             2.0   \n",
      "305             2.0             3.0       441.0         3.0             1.0   \n",
      "306             2.0             2.0       622.0         6.0             1.0   \n",
      "307             0.0             0.0       512.0         3.0             0.0   \n",
      "308             1.0             1.0       467.0         2.0             0.0   \n",
      "\n",
      "     G18USSDNEL  G18USSRSCO  G18GOVONPA County  \n",
      "304      1165.0      1465.0        14.0    BRO  \n",
      "305       427.0       312.0         6.0    BRO  \n",
      "306       583.0       492.0         5.0    BRO  \n",
      "307       501.0       320.0         0.0    BRO  \n",
      "308       444.0       530.0         2.0    BRO  \n"
     ]
    }
   ],
   "source": [
    "#Filter down the 2018 election results to the relevant counties where shapefiles are from VEST '16\n",
    "#(These are the only ones with a chance of matching)\n",
    "elections_vest16_counties = pivoted_2018[pivoted_2018['County'].isin(vest_2016_counties)]\n",
    "\n",
    "#See what it looks like\n",
    "print(elections_vest16_counties.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11 precincts that only appear in the elections\n",
      "There are 15 precincts that only appear in the shapefile\n",
      "There are 1561 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Merge shapefile with the election results\n",
    "merged_data_vest16 = pd.merge(elections_vest16_counties,shapefiles_vest_16,on=['Pct_std'],how='outer',indicator=True)\n",
    "vest_16_elections_only = merged_data_vest16[merged_data_vest16[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "vest_16_shapefile_only = merged_data_vest16[merged_data_vest16[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "vest_16_both = merged_data_vest16[merged_data_vest16[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "print(\"There are \" + str(vest_16_elections_only.count()) + \" precincts that only appear in the elections\")\n",
    "print(\"There are \" + str(vest_16_shapefile_only.count()) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(vest_16_both.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Census Redistricting Data Program (18 counties)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quote from the README:\n",
    "\n",
    "> \"Charlotte, Franklin, Glades, Hamilton, Holmes, Jackson, Jefferson, Levy, Liberty, Madison, Okeechobee, Orange, Seminole, Suwannee, Taylor, Wakulla, Walton, and Washinton come from the U.S. Census Bureau's 2020 Redistricting Data Program Phase 2 release.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When downloading from the Census redistricing data program, these use a FIPS code to identify counties\n",
    "\n",
    "fips_codes = [\"12015\",\"12037\",\"12043\",\"12047\",\"12059\",\"12063\",\"12065\",\"12075\",\"12077\",\"12079\",\"12093\",\n",
    "        \"12095\",\"12117\",\"12121\",\"12123\",\"12129\",\"12131\",\"12133\"]\n",
    "\n",
    "#Combine all the data from separate files into one\n",
    "li = []\n",
    "for i in fips_codes:\n",
    "    ref = \"./census/state_files/partnership_shapefiles_19v2_\"\n",
    "    file_ref = ref+i+\"/PVS_19_v2_vtd_\"+i+\".shp\"\n",
    "    file_prev = gp.read_file(file_ref)\n",
    "    li.append(file_prev)\n",
    "shapefiles_census = pd.concat(li, axis=0, ignore_index=True)\n",
    "#print(shapefiles_census.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  STATEFP COUNTYFP   VTDST            NAMELSAD VTDI LSAD CHNG_TYPE ORIG_NAME  \\\n",
      "0      12      015  000001   1-Voting District    A   00      None      None   \n",
      "1      12      015  000002   2-Voting District    A   00      None      None   \n",
      "2      12      015  000003   3-Voting District    A   00      None      None   \n",
      "3      12      015  000004   4-Voting District    A   00      None      None   \n",
      "4      12      015  000016  13-Voting District    A   00      None      None   \n",
      "\n",
      "  ORIG_CODE RELATE                NAME VINTAGE FUNCSTAT JUSTIFY  MTFCC  \\\n",
      "0      None   None   1-Voting District      90        N    None  G5240   \n",
      "1      None   None   2-Voting District      90        N    None  G5240   \n",
      "2      None   None   3-Voting District      90        N    None  G5240   \n",
      "3      None   None   4-Voting District      90        N    None  G5240   \n",
      "4      None   None  13-Voting District      90        N    None  G5240   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON Z ((-82.01288 26.96949 0.00000, -82.01...  \n",
      "1  POLYGON Z ((-82.02727 26.93930 0.00000, -82.02...  \n",
      "2  POLYGON Z ((-82.05635 26.94428 0.00000, -82.05...  \n",
      "3  POLYGON Z ((-82.07056 26.93519 0.00000, -82.06...  \n",
      "4  POLYGON Z ((-82.01888 26.94075 0.00000, -82.01...  \n"
     ]
    }
   ],
   "source": [
    "#Look at the data\n",
    "print(shapefiles_census.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a dictionary to convert from FIPS identifier to the 3 character county name\n",
    "county_code = {'015':\"CHA\", '037':\"FRA\", '043':\"GLA\", '047':\"HAM\", '059':\"HOL\", '063':\"JAC\", '065':\"JEF\", \n",
    "               '075':\"LEV\", '077':\"LIB\", '079':\"MAD\", '093':\"OKE\", '095':\"ORA\",\n",
    " '117':\"SEM\", '121':\"SUW\", '123':\"TAY\", '129':\"WAK\", '131':\"WAL\", '133':\"WAS\"}\n",
    "\n",
    "#Create a column with this 3-character county name\n",
    "shapefiles_census['county_name'] = shapefiles_census['COUNTYFP'].map(county_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using \"VTDST\" as the matcher, the outcome was:\n",
    "\n",
    ">There are 97 precincts that only appear in the election results  \n",
    "There are 190 precincts that only appear in the shapefile  \n",
    "There are 483 precincts that were matched between the two files  \n",
    "\n",
    "When using the first two digits of \"NAMELSAD\" as the matcher, the outcome was:\n",
    "\n",
    ">There are 281 precincts that only appear in the election results  \n",
    "There are 374 precincts that only appear in the shapefile  \n",
    "There are 299 precincts that were matched between the two files  \n",
    "\n",
    "Leads me to believe that \"VTDST\" is the better column to match on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOL0007    1\n",
      "TAY0014    1\n",
      "SEM0030    1\n",
      "ORA0211    1\n",
      "SEM0067    1\n",
      "          ..\n",
      "WAK0004    1\n",
      "ORA0140    1\n",
      "ORA0535    1\n",
      "ORA0217    1\n",
      "SEM0007    1\n",
      "Name: Pct_std, Length: 673, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Create a unique identifier, looks like \"VTDST\" is the best column to use for this, see above\n",
    "\n",
    "#Work on the \"NAMELSAD\" column to just store this as well\n",
    "shapefiles_census[\"NAMELSAD\"]= shapefiles_census[\"NAMELSAD\"].str.split(\"-\", n = 1, expand = True)\n",
    "\n",
    "#Take off the leading zero\n",
    "shapefiles_census[\"VTDST\"] = shapefiles_census[\"VTDST\"].str.lstrip('0')\n",
    "\n",
    "#Make sure they are all at least four digits\n",
    "shapefiles_census[\"VTDST\"] = shapefiles_census[\"VTDST\"].str.zfill(4)\n",
    "shapefiles_census[\"NAMELSAD\"] = shapefiles_census[\"NAMELSAD\"].str.zfill(4)\n",
    "\n",
    "#Create the unique identifier\n",
    "shapefiles_census[\"Pct_std\"]=shapefiles_census[\"county_name\"]+shapefiles_census[\"VTDST\"]\n",
    "shapefiles_census[\"alt_Pct_std\"]=shapefiles_census[\"county_name\"]+shapefiles_census[\"NAMELSAD\"]\n",
    "\n",
    "#Confirm that the unique identifier really is unique\n",
    "print(shapefiles_census[\"Pct_std\"].value_counts())\n",
    "\n",
    "#Filter the columns to only include 'Pct_std' and geometry\n",
    "shapefiles_census=shapefiles_census[[\"Pct_std\",\"geometry\"]]\n",
    "\n",
    "#Edit the CRS, so it matches that of the VEST file\n",
    "shapefiles_census = shapefiles_census.to_crs(vest_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter down the 2018 election results to the relevant counties where shapefiles are from the Census Redist. Data Program\n",
    "#(These are the only ones with a chance of matching)\n",
    "census_counties = [\"CHA\",\"FRA\",\"GLA\",\"HAM\",\"HOL\",\"JAC\",\"JEF\",\"LEV\",\"LIB\",\"MAD\",\"OKE\",\"ORA\",\"SEM\",\"SUW\",\"TAY\",\"WAK\",\"WAL\",\"WAS\"]\n",
    "election_census=pivoted_2018[pivoted_2018[\"County\"].isin(census_counties)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 97 precincts that only appear in the election results\n",
      "There are 190 precincts that only appear in the shapefile\n",
      "There are 483 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Merge the shapefile with election results\n",
    "merged_data_census = pd.merge(election_census,shapefiles_census,on=['Pct_std'],how='outer',indicator=True)\n",
    "census_elections_only = merged_data_census[merged_data_census[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "census_shapefile_only = merged_data_census[merged_data_census[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "census_both = merged_data_census[merged_data_census[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "print(\"There are \" + str(census_elections_only.count()) + \" precincts that only appear in the election results\")\n",
    "print(\"There are \" + str(census_shapefile_only.count()) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(census_both.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export these to CSV to compare, it doesn't seem like there is a simple fix for these\n",
    "census_elections_only_export = pd.Series(census_elections_only)\n",
    "census_elections_only_export.to_csv(\"./census_elections_only.csv\")\n",
    "\n",
    "census_shapefile_only.to_csv(\"./census_shapefile_only.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Counties themselves (16 counties - 14 mentioned in old README and 2 others from convo)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quote from README:\n",
    "\n",
    ">\"Collier, Flagler, Highlands, Hillsborough, Lake, Lee, Leon, Miami-Dade, Okaloosa, Osceola, Palm Beach, Pasco, Sumter, and Volusia come from the counties.\"\n",
    "\n",
    "Quote from Brian Amos on the other 2 counties:\n",
    "\n",
    ">\"Columbia and Duval were sent from their respective SOE offices\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I was able to find:\n",
    "\n",
    "- Collier - (downloaded) https://www.colliervotes.com/Voting-System-Maps-Stats/Precinct-Map-Voting-Boundaries     \n",
    "- Flagler - (downloaded) https://www.flaglerelections.com/For-Voters/District-Precinct-Maps   \n",
    "- Highlands - (not found)  \n",
    "- Hillsborough - (downloaded) https://www.votehillsborough.org/RESEARCH-DATA/Maps-Districts   \n",
    "- Lake - (not found)  \n",
    "- Lee - (downloaded) https://www.google.com/maps/d/viewer?mid=1FjtBs8SVp4PQjLmY09QUr9z-Pks&ll=26.559040386734967%2C-82.17803191789233&z=10  \n",
    "- Leon - (downloaded) https://geodata-tlcgis.opendata.arcgis.com/datasets/election-precincts-leon-county  \n",
    "- Miami-Dade  - (downloaded) https://gis-mdc.opendata.arcgis.com/datasets/precinct-1    \n",
    "- Okaloosa  - (downloaded) http://www.co.okaloosa.fl.us/gis_data  \n",
    "- Osceola  -  (couldn't find) https://www.voteosceola.com/en-us/Candidate-Information/Map-Files  \n",
    "- Palm Beach  -  (downloaded) https://www.pbcelections.org/Records-Data/Voting-District-Maps  \n",
    "- Pasco  -  (downloaded) https://www.pascocountyfl.net/342/GIS-Data-Shape-Files  \n",
    "- Sumter  - (couldn't find)  \n",
    "- Volusia  -  (couldn't find)  \n",
    "- Columbia -  (couldn't find)   \n",
    "- Duval -  (couldn't find)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Collier, I had to load the KML into Google Earth Pro and then export it to get the precinct labels to show up\n",
    "shapefiles_collier = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/counties/Precinct Boundaries_collier.kml\")\n",
    "flagler_pcts = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/counties/Flagler (2018-02-05)/VTDBLK_1_region.shp\")\n",
    "shapefiles_hillsborough = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/counties/HillsCtyElections-Various Files-2017 Shapefiles-2021015-3a3/2017ShapeFiles/PRECINCT12057_region.shp\")\n",
    "shapefiles_lee = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/counties/Lee County Precincts.kml\",driver='KML',split=\"<br>\")\n",
    "shapefiles_leon = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/counties/Election_Precincts_-_Leon_County-shp/Election_Precincts_-_Leon_County.shp\")\n",
    "shapefiles_miami = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/counties/Miami_Precinct-shp/Precinct.shp\")\n",
    "shapefiles_okaloosa = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/counties/Okaloosa County/precinct.shp\")\n",
    "shapefiles_palm = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/counties/Palm Beach SOE Shapefiles 2021/Precincts 2021.shp\")\n",
    "shapefiles_pasco = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/counties/Pasco VotingPrecincts_12112020_202012301214529224/VotingPrecincts_12112020.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 precincts that only appear in the election results\n",
      "There are 2 precincts that only appear in the shapefile\n",
      "There are 58 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Take a look at the file\n",
    "#print(shapefiles_collier.head())\n",
    "\n",
    "#The \"Name\" column seems like the best one to use, but needs to be cleaned\n",
    "#print(shapefiles_collier[\"Name\"])\n",
    "shapefiles_collier[\"Name\"] = shapefiles_collier[\"Name\"].str.replace('Precinct ','')\n",
    "\n",
    "#Make sure the name column has at least four characters\n",
    "shapefiles_collier[\"Name\"]= shapefiles_collier[\"Name\"].str.zfill(4)\n",
    "\n",
    "#Create the unique identifier\n",
    "shapefiles_collier[\"Pct_std\"]=\"CLL\"+shapefiles_collier[\"Name\"]\n",
    "\n",
    "#Filter the columns to only include 'Pct_std' and geometry\n",
    "shapefiles_collier=shapefiles_collier[[\"Pct_std\",\"geometry\"]]\n",
    "\n",
    "#Edit the CRS, so it matches that of the VEST file\n",
    "shapefiles_collier = shapefiles_collier.to_crs(vest_proj)\n",
    "\n",
    "#Filter down the election results\n",
    "election_collier = pivoted_2018[pivoted_2018[\"County\"]==\"CLL\"]\n",
    "\n",
    "#Merge data\n",
    "merged_data_collier = pd.merge(election_collier,shapefiles_collier,on=['Pct_std'],how='outer',indicator=True)\n",
    "collier_elections_only = merged_data_collier[merged_data_collier[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "collier_shapefile_only = merged_data_collier[merged_data_collier[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "collier_both = merged_data_collier[merged_data_collier[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "#Print diffrences\n",
    "print(\"There are \" + str(collier_elections_only.count()) + \" precincts that only appear in the election results\")\n",
    "print(\"There are \" + str(collier_shapefile_only.count()) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(collier_both.count()) + \" precincts that were matched between the two files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 precincts that only appear in the election results\n",
      "There are 1 precincts that only appear in the shapefile\n",
      "There are 25 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Take a look at the shapefile\n",
    "#print(flagler_pcts.head())\n",
    "#print(flagler_pcts.shape)\n",
    "\n",
    "#\"PRECINCT\" is the right column to use, but it isn't unique (needs to be grouped by this)\n",
    "#print(flagler_pcts[\"PRECINCT\"].value_counts())\n",
    "\n",
    "#Group by precinct # and reset index\n",
    "shapefiles_flagler = flagler_pcts.dissolve(by=\"PRECINCT\")\n",
    "shapefiles_flagler = shapefiles_flagler.reset_index()\n",
    "\n",
    "#Edit the precinct column to contain at least 4 character\n",
    "shapefiles_flagler[\"PRECINCT\"]= shapefiles_flagler[\"PRECINCT\"].str.zfill(4)\n",
    "\n",
    "#Create a unique identifer\n",
    "shapefiles_flagler[\"Pct_std\"]=\"FLA\"+shapefiles_flagler[\"PRECINCT\"]\n",
    "\n",
    "#Filter the columns to only include 'Pct_std' and geometry\n",
    "shapefiles_flagler=shapefiles_flagler[[\"Pct_std\",\"geometry\"]]\n",
    "\n",
    "#Edit the CRS, so it matches that of the VEST file\n",
    "shapefiles_flagler = shapefiles_flagler.to_crs(vest_proj)\n",
    "\n",
    "#Check this looks okay\n",
    "#print(shapefiles_flagler.head())\n",
    "\n",
    "#Filter down the election results\n",
    "election_flagler = pivoted_2018[pivoted_2018[\"County\"]==\"FLA\"]\n",
    "\n",
    "#Merge data\n",
    "merged_data_flagler = pd.merge(election_flagler,shapefiles_flagler,on=['Pct_std'],how='outer',indicator=True)\n",
    "flagler_elections_only = merged_data_flagler[merged_data_flagler[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "flagler_shapefile_only = merged_data_flagler[merged_data_flagler[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "flagler_both = merged_data_flagler[merged_data_flagler[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "#Print diffrences\n",
    "print(\"There are \" + str(flagler_elections_only.count()) + \" precincts that only appear in the election results\")\n",
    "print(\"There are \" + str(flagler_shapefile_only.count()) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(flagler_both.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 precincts that only appear in the election results\n",
      "There are 0 precincts that only appear in the shapefile\n",
      "There are 390 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Take a look\n",
    "#print(shapefiles_hillsborough.head())\n",
    "\n",
    "#Use the \"PRECINCT\" column\n",
    "#print(shapefiles_hillsborough[\"PRECINCT\"].shape)\n",
    "\n",
    "#Edit the precinct column to contain at least 4 character\n",
    "shapefiles_hillsborough[\"PRECINCT\"]= shapefiles_hillsborough[\"PRECINCT\"].str.zfill(4)\n",
    "\n",
    "#Create the unique identifer column\n",
    "shapefiles_hillsborough[\"Pct_std\"]=\"HIL\"+shapefiles_hillsborough[\"PRECINCT\"]\n",
    "\n",
    "#Filter the columns to only include 'Pct_std' and geometry\n",
    "shapefiles_hillsborough=shapefiles_hillsborough[[\"Pct_std\",\"geometry\"]]\n",
    "\n",
    "#Edit the CRS, so it matches that of the VEST file\n",
    "shapefiles_hillsborough = shapefiles_hillsborough.to_crs(vest_proj)\n",
    "\n",
    "#Filter down the election results\n",
    "election_hillsborough = pivoted_2018[pivoted_2018[\"County\"]==\"HIL\"]\n",
    "\n",
    "#Merge data\n",
    "merged_data_hillsborough = pd.merge(election_hillsborough,shapefiles_hillsborough,on=['Pct_std'],how='outer',indicator=True)\n",
    "hillsborough_elections_only = merged_data_hillsborough[merged_data_hillsborough[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "hillsborough_shapefile_only = merged_data_hillsborough[merged_data_hillsborough[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "hillsborough_both = merged_data_hillsborough[merged_data_hillsborough[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "#Print diffrences\n",
    "print(\"There are \" + str(hillsborough_elections_only.count()) + \" precincts that only appear in the election results\")\n",
    "print(\"There are \" + str(hillsborough_shapefile_only.count()) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(hillsborough_both.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 precincts that only appear in the election results\n",
      "There are 0 precincts that only appear in the shapefile\n",
      "There are 127 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Take a look\n",
    "#print(shapefiles_lee.head())\n",
    "\n",
    "#From examining the map, only concerned with those that don't start with \"()\", as those designate a voting place, not an entire precinct\n",
    "shapefiles_lee[\"First_char\"] = shapefiles_lee[\"Name\"].astype(str).str[0]==\"(\"\n",
    "shapefiles_lee = shapefiles_lee[shapefiles_lee[\"First_char\"]==False]\n",
    "\n",
    "#Now can use the \"Name\" column to create the unique identifier\n",
    "shapefiles_lee[\"Name\"]= shapefiles_lee[\"Name\"].str.zfill(4)\n",
    "\n",
    "#Create the unique identifer column\n",
    "shapefiles_lee[\"Pct_std\"]=\"LEE\"+shapefiles_lee[\"Name\"]\n",
    "\n",
    "#Filter the columns to only include 'Pct_std' and geometry\n",
    "shapefiles_lee=shapefiles_lee[[\"Pct_std\",\"geometry\"]]\n",
    "\n",
    "#Edit the CRS, so it matches that of the VEST file\n",
    "shapefiles_lee = shapefiles_lee.to_crs(vest_proj)\n",
    "\n",
    "#Filter down the election results\n",
    "election_lee = pivoted_2018[pivoted_2018[\"County\"]==\"LEE\"]\n",
    "\n",
    "#Merge data\n",
    "merged_data_lee = pd.merge(election_lee,shapefiles_lee,on=['Pct_std'],how='outer',indicator=True)\n",
    "lee_elections_only = merged_data_lee[merged_data_lee[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "lee_shapefile_only = merged_data_lee[merged_data_lee[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "lee_both = merged_data_lee[merged_data_lee[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "#Print diffrences\n",
    "print(\"There are \" + str(lee_elections_only.count()) + \" precincts that only appear in the election results\")\n",
    "print(\"There are \" + str(lee_shapefile_only.count()) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(lee_both.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 precincts that only appear in the election results\n",
      "There are 9 precincts that only appear in the shapefile\n",
      "There are 155 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Take a look at the file\n",
    "#print(shapefiles_leon.head())\n",
    "\n",
    "#Edit the precinct column to contain at least 4 character\n",
    "shapefiles_leon[\"PRECINCT\"]= shapefiles_leon[\"PRECINCT\"].str.zfill(4)\n",
    "\n",
    "#Create the unique identifer column\n",
    "shapefiles_leon[\"Pct_std\"]=\"LEO\"+shapefiles_leon[\"PRECINCT\"]\n",
    "\n",
    "#Filter the columns to only include 'Pct_std' and geometry\n",
    "shapefiles_leon=shapefiles_leon[[\"Pct_std\",\"geometry\"]]\n",
    "\n",
    "#Edit the CRS, so it matches that of the VEST file\n",
    "shapefiles_leon = shapefiles_leon.to_crs(vest_proj)\n",
    "\n",
    "#Filter down the election results\n",
    "election_leon = pivoted_2018[pivoted_2018[\"County\"]==\"LEO\"]\n",
    "\n",
    "#Merge data\n",
    "merged_data_leon = pd.merge(election_leon,shapefiles_leon,on=['Pct_std'],how='outer',indicator=True)\n",
    "leon_elections_only = merged_data_leon[merged_data_leon[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "leon_shapefile_only = merged_data_leon[merged_data_leon[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "leon_both = merged_data_leon[merged_data_leon[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "#Print diffrences\n",
    "print(\"There are \" + str(leon_elections_only.count()) + \" precincts that only appear in the election results\")\n",
    "print(\"There are \" + str(leon_shapefile_only.count()) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(leon_both.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 precincts that only appear in the election results\n",
      "There are 0 precincts that only appear in the shapefile\n",
      "There are 783 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Take a look, looks like \"ID\" is an okay column to use\n",
    "#print(shapefiles_miami.head())\n",
    "\n",
    "#Convert the ID column to contain at least 4 character\n",
    "shapefiles_miami[\"ID\"] = shapefiles_miami[\"ID\"].apply(str)\n",
    "shapefiles_miami[\"ID\"] = shapefiles_miami[\"ID\"].str.zfill(4)\n",
    "\n",
    "#Create the unique identifer column\n",
    "shapefiles_miami[\"Pct_std\"]=\"DAD\"+shapefiles_miami[\"ID\"]\n",
    "\n",
    "#Filter the columns to only include 'Pct_std' and geometry\n",
    "shapefiles_miami=shapefiles_miami[[\"Pct_std\",\"geometry\"]]\n",
    "\n",
    "#Edit the CRS, so it matches that of the VEST file\n",
    "shapefiles_miami = shapefiles_miami.to_crs(vest_proj)\n",
    "\n",
    "#Filter down the election results\n",
    "election_miami = pivoted_2018[pivoted_2018[\"County\"]==\"DAD\"]\n",
    "\n",
    "#Merge data\n",
    "merged_data_miami = pd.merge(election_miami,shapefiles_miami,on=['Pct_std'],how='outer',indicator=True)\n",
    "miami_elections_only = merged_data_miami[merged_data_miami[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "miami_shapefile_only = merged_data_miami[merged_data_miami[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "miami_both = merged_data_miami[merged_data_miami[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "#Print diffrences\n",
    "print(\"There are \" + str(miami_elections_only.count()) + \" precincts that only appear in the election results\")\n",
    "print(\"There are \" + str(miami_shapefile_only.count()) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(miami_both.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 precincts that only appear in the election results\n",
      "There are 0 precincts that only appear in the shapefile\n",
      "There are 52 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Take a look\n",
    "#print(shapefiles_okaloosa.head())\n",
    "\n",
    "#Looks like \"NO\" is the right column, convert to string and edit to contain at least 4 characters\n",
    "shapefiles_okaloosa[\"NO\"] = shapefiles_okaloosa[\"NO\"].apply(str)\n",
    "shapefiles_okaloosa[\"NO\"] = shapefiles_okaloosa[\"NO\"].str.zfill(4)\n",
    "\n",
    "#Create the unique identifer column\n",
    "shapefiles_okaloosa[\"Pct_std\"]=\"OKA\"+shapefiles_okaloosa[\"NO\"]\n",
    "\n",
    "#Filter the columns to only include 'Pct_std' and geometry\n",
    "shapefiles_okaloosa=shapefiles_okaloosa[[\"Pct_std\",\"geometry\"]]\n",
    "\n",
    "#Edit the CRS, so it matches that of the VEST file\n",
    "shapefiles_okaloosa = shapefiles_okaloosa.to_crs(vest_proj)\n",
    "\n",
    "#Filter down the election results\n",
    "election_okaloosa = pivoted_2018[pivoted_2018[\"County\"]==\"OKA\"]\n",
    "\n",
    "#Merge data\n",
    "merged_data_okaloosa = pd.merge(election_okaloosa,shapefiles_okaloosa,on=['Pct_std'],how='outer',indicator=True)\n",
    "okaloosa_elections_only = merged_data_okaloosa[merged_data_okaloosa[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "okaloosa_shapefile_only = merged_data_okaloosa[merged_data_okaloosa[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "okaloosa_both = merged_data_okaloosa[merged_data_okaloosa[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "#Print diffrences\n",
    "print(\"There are \" + str(okaloosa_elections_only.count()) + \" precincts that only appear in the election results\")\n",
    "print(\"There are \" + str(okaloosa_shapefile_only.count()) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(okaloosa_both.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 precincts that only appear in the election results\n",
      "There are 4 precincts that only appear in the shapefile\n",
      "There are 868 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Take a look, looks like \"PRECINCT\" is the column to use\n",
    "#print(shapefiles_palm.head())\n",
    "\n",
    "#Edit the precinct column to contain at least 4 character\n",
    "shapefiles_palm[\"PRECINCT\"]= shapefiles_palm[\"PRECINCT\"].str.zfill(4)\n",
    "\n",
    "#Create the unique identifer column\n",
    "shapefiles_palm[\"Pct_std\"]=\"PAL\"+shapefiles_palm[\"PRECINCT\"]\n",
    "\n",
    "#Filter the columns to only include 'Pct_std' and geometry\n",
    "shapefiles_palm=shapefiles_palm[[\"Pct_std\",\"geometry\"]]\n",
    "\n",
    "#Edit the CRS, so it matches that of the VEST file\n",
    "shapefiles_palm = shapefiles_palm.to_crs(vest_proj)\n",
    "\n",
    "#Filter down the election results\n",
    "election_palm = pivoted_2018[pivoted_2018[\"County\"]==\"PAL\"]\n",
    "\n",
    "#Merge data\n",
    "merged_data_palm = pd.merge(election_palm,shapefiles_palm,on=['Pct_std'],how='outer',indicator=True)\n",
    "palm_elections_only = merged_data_palm[merged_data_palm[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "palm_shapefile_only = merged_data_palm[merged_data_palm[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "palm_both = merged_data_palm[merged_data_palm[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "#Print diffrences\n",
    "print(\"There are \" + str(palm_elections_only.count()) + \" precincts that only appear in the election results\")\n",
    "print(\"There are \" + str(palm_shapefile_only.count()) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(palm_both.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 precincts that only appear in the election results\n",
      "There are 43 precincts that only appear in the shapefile\n",
      "There are 109 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Take a look\n",
    "#print(shapefiles_pasco.head())\n",
    "\n",
    "#Seems like \"Precinct\" is the right column to use and that it is a unique value\n",
    "#print(shapefiles_pasco[\"Precinct\"].value_counts())\n",
    "\n",
    "#Edit the precinct column to contain at least 4 character\n",
    "shapefiles_pasco[\"Precinct\"]= shapefiles_pasco[\"Precinct\"].str.zfill(4)\n",
    "\n",
    "#Create the unique identifer column\n",
    "shapefiles_pasco[\"Pct_std\"]=\"PAS\"+shapefiles_pasco[\"Precinct\"]\n",
    "\n",
    "#Filter the columns to only include 'Pct_std' and geometry\n",
    "shapefiles_pasco=shapefiles_pasco[[\"Pct_std\",\"geometry\"]]\n",
    "\n",
    "#Take out that doesn't have any geometry (causing an issue)\n",
    "shapefiles_pasco= shapefiles_pasco.drop([99])\n",
    "\n",
    "#Edit the CRS, so it matches that of the VEST file\n",
    "shapefiles_pasco = shapefiles_pasco.to_crs(vest_proj)\n",
    "\n",
    "#Filter down the election results\n",
    "election_pasco = pivoted_2018[pivoted_2018[\"County\"]==\"PAS\"]\n",
    "\n",
    "#Merge data\n",
    "merged_data_pasco = pd.merge(election_pasco,shapefiles_pasco,on=['Pct_std'],how='outer',indicator=True)\n",
    "pasco_elections_only = merged_data_pasco[merged_data_pasco[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "pasco_shapefile_only = merged_data_pasco[merged_data_pasco[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "pasco_both = merged_data_pasco[merged_data_pasco[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "#Print diffrences\n",
    "print(\"There are \" + str(pasco_elections_only.count()) + \" precincts that only appear in the election results\")\n",
    "print(\"There are \" + str(pasco_shapefile_only.count()) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(pasco_both.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of Election and Precinct Data Matching**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the election results, there are 5,999 rows.\n",
    "\n",
    "For the shapefiles, the data is split among 4 categories, w/ each county being in one of these 4 categories:\n",
    "    1. Florida Department of State records request (16 counties, no data from any of these)\n",
    "    2. VEST '16 data file (17 counties, data from all of these)\n",
    "    3. Census Redistricting Data Program (18 counties, data from all of these)\n",
    "    4. Counties themselves (16 counties, data from 9 of these)\n",
    "    \n",
    "Summarizing the above, there are 23 counties where we were not able to obtain shapefile data\n",
    "\n",
    ">\"Alachua, Baker, Bay, Bradford, Brevard, Calhoun, Citrus, Clay, Dixie, Escambia, Hardee, Hendry, Hernando, Indian River, Lafayette and Sarasota come from the Department of State.\"\n",
    "\n",
    "> Highlands, Lake, Osceola, Sumter, Volusia, Columbia, Duval all were not found from the counties themselves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1272, 42)\n"
     ]
    }
   ],
   "source": [
    "#Making a list of the counties w/o shapefile data\n",
    "counties_no_shapefiles = [\"ALA\",\"BAK\",\"BAY\",\"BRA\",\"BRE\",\"CAL\",\"CIT\",\"CLA\",\"DIX\",\"ESC\",\"HAR\",\"HEN\",\"HER\",\"IND\",\"LAF\",\"SAR\",\"HIG\",\"LAK\",\"OSC\",\"SUM\",\"VOL\",\"CLM\",\"DUV\"]\n",
    "\n",
    "#Filtering out these counties' election results\n",
    "election_no_shapefiles = pivoted_2018[pivoted_2018[\"County\"].isin(counties_no_shapefiles)]\n",
    "\n",
    "#Counting how many rows this includes\n",
    "print(election_no_shapefiles.shape)\n",
    "\n",
    "#There are 1272 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the VEST '16 data:\n",
    "\n",
    "> - There are 11 precincts that only appear in the election results  \n",
    "- There are 15 precincts that only appear in the shapefile\n",
    "- There are 1561 precincts that were matched between the two files\n",
    "\n",
    "From the Census Redistricting Data Program:\n",
    "\n",
    "> - There are 97 precincts that only appear in the election results\n",
    "- There are 190 precincts that only appear in the shapefile\n",
    "- There are 483 precincts that were matched between the two files\n",
    "\n",
    "From the counties themselves:  \n",
    "Format being (# w/ only election, # w/ only shapefile, #matched)\n",
    "\n",
    "- Collier      (1,2,58)\n",
    "- Flagler      (1,1,25)\n",
    "- Hillsborough (0,0,390)\n",
    "- Lee          (0,0,127)\n",
    "- Leon         (0,9,155)\n",
    "- Miami-Dade   (0,0,783)\n",
    "- Okaloosa     (0,0,52)\n",
    "- Palm         (5,4,868)\n",
    "- Pasco        (1,43,109)\n",
    "- **Total:     (8,59,2567)** \n",
    "\n",
    "Sanity check (these numbers should add up to 5,999):\n",
    "\n",
    "- 1272+11+1561+97+483+8+2567 = 5,999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a unified file**\n",
    "\n",
    "All files should have the same number of columns, but will check.\n",
    "From there, the \"_merge\" value will tell us what it contains:\n",
    "\n",
    "- 'both': election results + shapefile\n",
    "- 'left_only': just election results\n",
    "- 'right_only': just a shapefile\n",
    "\n",
    "Relevant files are in the list below (there should be 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1272, 42)\n",
      "(1587, 44)\n",
      "(770, 44)\n",
      "(61, 44)\n",
      "(27, 44)\n",
      "(390, 44)\n",
      "(127, 44)\n",
      "(164, 44)\n",
      "(783, 44)\n",
      "(52, 44)\n",
      "(877, 44)\n",
      "(153, 44)\n",
      "Index(['Pct_std', 'G18A10NO', 'G18A10YES', 'G18A11NO', 'G18A11YES', 'G18A12NO',\n",
      "       'G18A12YES', 'G18A13NO', 'G18A13YES', 'G18A01NO', 'G18A01YES',\n",
      "       'G18A02NO', 'G18A02YES', 'G18A03NO', 'G18A03YES', 'G18A04NO',\n",
      "       'G18A04YES', 'G18A05NO', 'G18A05YES', 'G18A06NO', 'G18A06YES',\n",
      "       'G18A07NO', 'G18A07YES', 'G18A09NO', 'G18A09YES', 'G18ATGRMOO',\n",
      "       'G18ATGOSIS', 'G18ATGDSHA', 'G18CFODRIN', 'G18CFORPAT', 'G18AGRRCAL',\n",
      "       'G18AGRDFRI', 'G18GOVRDES', 'G18GOV_to_add1', 'G18GOV_to_add2',\n",
      "       'G18GOVDGIL', 'G18GOVORIC', 'G18GOV_to_add3', 'G18USSDNEL',\n",
      "       'G18USSRSCO', 'G18GOVONPA', 'County'],\n",
      "      dtype='object')\n",
      "Index(['Pct_std', 'G18A10NO', 'G18A10YES', 'G18A11NO', 'G18A11YES', 'G18A12NO',\n",
      "       'G18A12YES', 'G18A13NO', 'G18A13YES', 'G18A01NO', 'G18A01YES',\n",
      "       'G18A02NO', 'G18A02YES', 'G18A03NO', 'G18A03YES', 'G18A04NO',\n",
      "       'G18A04YES', 'G18A05NO', 'G18A05YES', 'G18A06NO', 'G18A06YES',\n",
      "       'G18A07NO', 'G18A07YES', 'G18A09NO', 'G18A09YES', 'G18ATGRMOO',\n",
      "       'G18ATGOSIS', 'G18ATGDSHA', 'G18CFODRIN', 'G18CFORPAT', 'G18AGRRCAL',\n",
      "       'G18AGRDFRI', 'G18GOVRDES', 'G18GOV_to_add1', 'G18GOV_to_add2',\n",
      "       'G18GOVDGIL', 'G18GOVORIC', 'G18GOV_to_add3', 'G18USSDNEL',\n",
      "       'G18USSRSCO', 'G18GOVONPA', 'County', 'geometry', '_merge'],\n",
      "      dtype='object')\n",
      "(1272, 44)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True]\n",
      "(6263, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-47-eaeeaaa1b7ef>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  election_no_shapefiles[\"geometry\"]=None\n",
      "<ipython-input-47-eaeeaaa1b7ef>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  election_no_shapefiles[\"_merge\"]=\"No shapefile available\"\n"
     ]
    }
   ],
   "source": [
    "files_to_combine=[election_no_shapefiles,merged_data_vest16,merged_data_census,\n",
    "                merged_data_collier,merged_data_flagler,merged_data_hillsborough,\n",
    "                 merged_data_lee,merged_data_leon,merged_data_miami,\n",
    "                 merged_data_okaloosa,merged_data_palm,merged_data_pasco]\n",
    "\n",
    " \n",
    "#Clean up the columns of these files so we can concatenate them all together\n",
    "for i in files_to_combine:\n",
    "    print(i.shape)\n",
    "\n",
    "#Note that \"election_no_shapefiles\" only has 2 fewer columns, because it has no geometry (even a null one)\n",
    "#and has not been involved in any merge\n",
    "\n",
    "#Also note there are 6,263 total rows, something to check after the concat\n",
    "print(election_no_shapefiles.columns)\n",
    "print(merged_data_lee.columns)\n",
    "\n",
    "election_no_shapefiles[\"geometry\"]=None\n",
    "election_no_shapefiles[\"_merge\"]=\"No shapefile available\"\n",
    "\n",
    "#Now the shapes should all be equal\n",
    "print(election_no_shapefiles.shape)\n",
    "\n",
    "#Check to make sure the column names are equal so they can be concatenated\n",
    "for i in range(0,len(files_to_combine)-1):\n",
    "    print(files_to_combine[i].columns==files_to_combine[i+1].columns)\n",
    "    \n",
    "pdv_unified = pd.concat(files_to_combine, axis=0, ignore_index=True)\n",
    "print(pdv_unified.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pct_std  G18A10NO  G18A10YES  G18A11NO  G18A11YES  G18A12NO  G18A12YES  \\\n",
      "0  ALA0001     367.0      500.0     421.0      434.0     254.0      613.0   \n",
      "1  ALA0002     563.0      743.0     619.0      667.0     449.0      879.0   \n",
      "2  ALA0003    1096.0     1476.0    1161.0     1348.0     730.0     1884.0   \n",
      "3  ALA0004     811.0     1169.0     893.0     1068.0     618.0     1392.0   \n",
      "4  ALA0005    1178.0      631.0     888.0      906.0     671.0     1181.0   \n",
      "\n",
      "   G18A13NO  G18A13YES  G18A01NO  G18A01YES  G18A02NO  G18A02YES  G18A03NO  \\\n",
      "0     414.0      476.0     420.0      464.0     357.0      512.0     236.0   \n",
      "1     600.0      748.0     651.0      702.0     571.0      760.0     346.0   \n",
      "2    1013.0     1640.0    1141.0     1525.0     988.0     1625.0     731.0   \n",
      "3     962.0     1081.0     799.0     1244.0     643.0     1382.0     635.0   \n",
      "4     383.0     1554.0    1313.0      562.0    1138.0      708.0     505.0   \n",
      "\n",
      "   G18A03YES  G18A04NO  G18A04YES  G18A05NO  G18A05YES  G18A06NO  G18A06YES  \\\n",
      "0      659.0     375.0      526.0     301.0      576.0     386.0      502.0   \n",
      "1     1015.0     551.0      816.0     531.0      806.0     634.0      708.0   \n",
      "2     1939.0    1134.0     1539.0     941.0     1692.0    1255.0     1383.0   \n",
      "3     1416.0     975.0     1077.0     627.0     1403.0     908.0     1115.0   \n",
      "4     1405.0     313.0     1642.0    1199.0      681.0    1251.0      616.0   \n",
      "\n",
      "   G18A07NO  G18A07YES  G18A09NO  G18A09YES  G18ATGRMOO  G18ATGOSIS  \\\n",
      "0     387.0      490.0     358.0      529.0       563.0        17.0   \n",
      "1     600.0      747.0     552.0      799.0       762.0        32.0   \n",
      "2    1072.0     1557.0    1021.0     1616.0      1646.0        42.0   \n",
      "3     813.0     1216.0     897.0     1124.0      1408.0        24.0   \n",
      "4    1117.0      758.0     384.0     1543.0       483.0        38.0   \n",
      "\n",
      "   G18ATGDSHA  G18CFODRIN  G18CFORPAT  G18AGRRCAL  G18AGRDFRI  G18GOVRDES  \\\n",
      "0       323.0       348.0       539.0       545.0       347.0       544.0   \n",
      "1       584.0       617.0       740.0       740.0       622.0       739.0   \n",
      "2      1022.0      1102.0      1563.0      1592.0      1100.0      1592.0   \n",
      "3       629.0       677.0      1358.0      1356.0       687.0      1372.0   \n",
      "4      1412.0      1397.0       509.0       448.0      1471.0       438.0   \n",
      "\n",
      "   G18GOV_to_add1  G18GOV_to_add2  G18GOVDGIL  G18GOVORIC  G18GOV_to_add3  \\\n",
      "0             3.0             4.0       357.0         2.0             0.0   \n",
      "1             1.0             4.0       622.0        12.0             8.0   \n",
      "2             4.0             8.0      1123.0        13.0             4.0   \n",
      "3             6.0             7.0       688.0         8.0             4.0   \n",
      "4             2.0             5.0      1525.0         7.0             4.0   \n",
      "\n",
      "   G18USSDNEL  G18USSRSCO  G18GOVONPA County geometry                  _merge  \n",
      "0       372.0       532.0         7.0    ALA     None  No shapefile available  \n",
      "1       662.0       717.0        13.0    ALA     None  No shapefile available  \n",
      "2      1192.0      1541.0        16.0    ALA     None  No shapefile available  \n",
      "3       767.0      1320.0        17.0    ALA     None  No shapefile available  \n",
      "4      1545.0       433.0        11.0    ALA     None  No shapefile available  \n"
     ]
    }
   ],
   "source": [
    "print(pdv_unified.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 260 precincts that only appear in the sourcefiles\n",
      "There are 4 precincts that only appear in the vest file\n",
      "There are 6069 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Merge the two files\n",
    "merged_data_everything = pd.merge(pdv_unified,vest_fl,on=['Pct_std'],how='outer',indicator=\"main_merge\")\n",
    "sourcefiles_only = merged_data_everything[merged_data_everything[\"main_merge\"]==\"left_only\"]['Pct_std']\n",
    "vest_file_only = merged_data_everything[merged_data_everything[\"main_merge\"]==\"right_only\"]['Pct_std']\n",
    "both_files = merged_data_everything[merged_data_everything[\"main_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "#Print diffrences\n",
    "print(\"There are \" + str(sourcefiles_only.count()) + \" precincts that only appear in the sourcefiles\")\n",
    "print(\"There are \" + str(vest_file_only.count()) + \" precincts that only appear in the vest file\")\n",
    "print(\"There are \" + str(both_files.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6073, 43)\n"
     ]
    }
   ],
   "source": [
    "#Sanity Check, there should be 6073 rows in the vest file\n",
    "print(vest_fl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pct_std  G18A10NO_x  G18A10YES_x  G18A11NO_x  G18A11YES_x  G18A12NO_x  \\\n",
      "0  ALA0001       367.0        500.0       421.0        434.0       254.0   \n",
      "1  ALA0002       563.0        743.0       619.0        667.0       449.0   \n",
      "2  ALA0003      1096.0       1476.0      1161.0       1348.0       730.0   \n",
      "3  ALA0004       811.0       1169.0       893.0       1068.0       618.0   \n",
      "4  ALA0005      1178.0        631.0       888.0        906.0       671.0   \n",
      "\n",
      "   G18A12YES_x  G18A13NO_x  G18A13YES_x  G18A01NO_x  G18A01YES_x  G18A02NO_x  \\\n",
      "0        613.0       414.0        476.0       420.0        464.0       357.0   \n",
      "1        879.0       600.0        748.0       651.0        702.0       571.0   \n",
      "2       1884.0      1013.0       1640.0      1141.0       1525.0       988.0   \n",
      "3       1392.0       962.0       1081.0       799.0       1244.0       643.0   \n",
      "4       1181.0       383.0       1554.0      1313.0        562.0      1138.0   \n",
      "\n",
      "   G18A02YES_x  G18A03NO_x  G18A03YES_x  G18A04NO_x  G18A04YES_x  G18A05NO_x  \\\n",
      "0        512.0       236.0        659.0       375.0        526.0       301.0   \n",
      "1        760.0       346.0       1015.0       551.0        816.0       531.0   \n",
      "2       1625.0       731.0       1939.0      1134.0       1539.0       941.0   \n",
      "3       1382.0       635.0       1416.0       975.0       1077.0       627.0   \n",
      "4        708.0       505.0       1405.0       313.0       1642.0      1199.0   \n",
      "\n",
      "   G18A05YES_x  G18A06NO_x  G18A06YES_x  G18A07NO_x  G18A07YES_x  G18A09NO_x  \\\n",
      "0        576.0       386.0        502.0       387.0        490.0       358.0   \n",
      "1        806.0       634.0        708.0       600.0        747.0       552.0   \n",
      "2       1692.0      1255.0       1383.0      1072.0       1557.0      1021.0   \n",
      "3       1403.0       908.0       1115.0       813.0       1216.0       897.0   \n",
      "4        681.0      1251.0        616.0      1117.0        758.0       384.0   \n",
      "\n",
      "   G18A09YES_x  G18ATGRMOO_x  G18ATGOSIS_x  G18ATGDSHA_x  G18CFODRIN_x  \\\n",
      "0        529.0         563.0          17.0         323.0         348.0   \n",
      "1        799.0         762.0          32.0         584.0         617.0   \n",
      "2       1616.0        1646.0          42.0        1022.0        1102.0   \n",
      "3       1124.0        1408.0          24.0         629.0         677.0   \n",
      "4       1543.0         483.0          38.0        1412.0        1397.0   \n",
      "\n",
      "   G18CFORPAT_x  G18AGRRCAL_x  G18AGRDFRI_x  G18GOVRDES_x  G18GOV_to_add1  \\\n",
      "0         539.0         545.0         347.0         544.0             3.0   \n",
      "1         740.0         740.0         622.0         739.0             1.0   \n",
      "2        1563.0        1592.0        1100.0        1592.0             4.0   \n",
      "3        1358.0        1356.0         687.0        1372.0             6.0   \n",
      "4         509.0         448.0        1471.0         438.0             2.0   \n",
      "\n",
      "   G18GOV_to_add2  G18GOVDGIL_x  G18GOVORIC_x  G18GOV_to_add3  G18USSDNEL_x  \\\n",
      "0             4.0         357.0           2.0             0.0         372.0   \n",
      "1             4.0         622.0          12.0             8.0         662.0   \n",
      "2             8.0        1123.0          13.0             4.0        1192.0   \n",
      "3             7.0         688.0           8.0             4.0         767.0   \n",
      "4             5.0        1525.0           7.0             4.0        1545.0   \n",
      "\n",
      "   G18USSRSCO_x  G18GOVONPA_x County_x geometry_x                  _merge  \\\n",
      "0         532.0           7.0      ALA       None  No shapefile available   \n",
      "1         717.0          13.0      ALA       None  No shapefile available   \n",
      "2        1541.0          16.0      ALA       None  No shapefile available   \n",
      "3        1320.0          17.0      ALA       None  No shapefile available   \n",
      "4         433.0          11.0      ALA       None  No shapefile available   \n",
      "\n",
      "  County_y Precnct  G18USSRSCO_y  G18USSDNEL_y  G18GOVRDES_y  G18GOVDGIL_y  \\\n",
      "0      ALA      01         532.0         372.0         544.0         357.0   \n",
      "1      ALA      02         717.0         662.0         739.0         622.0   \n",
      "2      ALA      03        1541.0        1192.0        1592.0        1123.0   \n",
      "3      ALA      04        1320.0         767.0        1372.0         688.0   \n",
      "4      ALA      05         433.0        1545.0         438.0        1525.0   \n",
      "\n",
      "   G18GOVORIC_y  G18GOVONPA_y  G18ATGRMOO_y  G18ATGDSHA_y  G18ATGOSIS_y  \\\n",
      "0           2.0           7.0         563.0         323.0          17.0   \n",
      "1          12.0          13.0         762.0         584.0          32.0   \n",
      "2          13.0          16.0        1646.0        1022.0          42.0   \n",
      "3           8.0          17.0        1408.0         629.0          24.0   \n",
      "4           7.0          11.0         483.0        1412.0          38.0   \n",
      "\n",
      "   G18CFORPAT_y  G18CFODRIN_y  G18AGRRCAL_y  G18AGRDFRI_y  G18A01YES_y  \\\n",
      "0         539.0         348.0         545.0         347.0        464.0   \n",
      "1         740.0         617.0         740.0         622.0        702.0   \n",
      "2        1563.0        1102.0        1592.0        1100.0       1525.0   \n",
      "3        1358.0         677.0        1356.0         687.0       1244.0   \n",
      "4         509.0        1397.0         448.0        1471.0        562.0   \n",
      "\n",
      "   G18A01NO_y  G18A02YES_y  G18A02NO_y  G18A03YES_y  G18A03NO_y  G18A04YES_y  \\\n",
      "0       420.0        512.0       357.0        659.0       236.0        526.0   \n",
      "1       651.0        760.0       571.0       1015.0       346.0        816.0   \n",
      "2      1141.0       1625.0       988.0       1939.0       731.0       1539.0   \n",
      "3       799.0       1382.0       643.0       1416.0       635.0       1077.0   \n",
      "4      1313.0        708.0      1138.0       1405.0       505.0       1642.0   \n",
      "\n",
      "   G18A04NO_y  G18A05YES_y  G18A05NO_y  G18A06YES_y  G18A06NO_y  G18A07YES_y  \\\n",
      "0       375.0        576.0       301.0        502.0       386.0        490.0   \n",
      "1       551.0        806.0       531.0        708.0       634.0        747.0   \n",
      "2      1134.0       1692.0       941.0       1383.0      1255.0       1557.0   \n",
      "3       975.0       1403.0       627.0       1115.0       908.0       1216.0   \n",
      "4       313.0        681.0      1199.0        616.0      1251.0        758.0   \n",
      "\n",
      "   G18A07NO_y  G18A09YES_y  G18A09NO_y  G18A10YES_y  G18A10NO_y  G18A11YES_y  \\\n",
      "0       387.0        529.0       358.0        500.0       367.0        434.0   \n",
      "1       600.0        799.0       552.0        743.0       563.0        667.0   \n",
      "2      1072.0       1616.0      1021.0       1476.0      1096.0       1348.0   \n",
      "3       813.0       1124.0       897.0       1169.0       811.0       1068.0   \n",
      "4      1117.0       1543.0       384.0        631.0      1178.0        906.0   \n",
      "\n",
      "   G18A11NO_y  G18A12YES_y  G18A12NO_y  G18A13YES_y  G18A13NO_y  \\\n",
      "0       421.0        613.0       254.0        476.0       414.0   \n",
      "1       619.0        879.0       449.0        748.0       600.0   \n",
      "2      1161.0       1884.0       730.0       1640.0      1013.0   \n",
      "3       893.0       1392.0       618.0       1081.0       962.0   \n",
      "4       888.0       1181.0       671.0       1554.0       383.0   \n",
      "\n",
      "                                          geometry_y    check confirm  \\\n",
      "0  POLYGON ((-82.24245 29.85246, -82.24106 29.852...  ALA0001    True   \n",
      "1  POLYGON ((-82.41775 29.92248, -82.41711 29.922...  ALA0002    True   \n",
      "2  POLYGON ((-82.53335 29.84801, -82.52809 29.838...  ALA0003    True   \n",
      "3  POLYGON ((-82.55700 29.65461, -82.55638 29.654...  ALA0004    True   \n",
      "4  POLYGON ((-82.34441 29.66672, -82.34334 29.666...  ALA0005    True   \n",
      "\n",
      "  main_merge  \n",
      "0       both  \n",
      "1       both  \n",
      "2       both  \n",
      "3       both  \n",
      "4       both  \n",
      "(1271, 87)\n",
      "(101, 87)\n",
      "(86, 87)\n",
      "(4611, 87)\n"
     ]
    }
   ],
   "source": [
    "#From the above, 6069 precincts were matched in some capacity \n",
    "#I.e not all of them will include election results and a shapefile\n",
    "\n",
    "print(merged_data_everything[merged_data_everything[\"main_merge\"]==\"both\"].head())\n",
    "\n",
    "#1217 rows where there is a match but there was no shapefile data available\n",
    "print(merged_data_everything[(merged_data_everything[\"main_merge\"]==\"both\") & (merged_data_everything[\"_merge\"]==\"No shapefile available\")].shape)\n",
    "\n",
    "#101 rows where there is a match, but weren't able to find the shapefile\n",
    "print(merged_data_everything[(merged_data_everything[\"main_merge\"]==\"both\") & (merged_data_everything[\"_merge\"]==\"left_only\")].shape)\n",
    "\n",
    "#86 rows where there is a match, but no election results\n",
    "print(merged_data_everything[(merged_data_everything[\"main_merge\"]==\"both\") & (merged_data_everything[\"_merge\"]==\"right_only\")].shape)\n",
    "\n",
    "#4611 rows where there is a match and both shapefile and election results\n",
    "print(merged_data_everything[(merged_data_everything[\"main_merge\"]==\"both\") & (merged_data_everything[\"_merge\"]==\"both\")].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not totally sure how to compare the geometries here\n",
    "#merged_data_everything[\"geometry_x\"].almost_equals(merged_data_everything[\"geometry_x\"],decimal = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing Election Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validater_row (df, column_List):\n",
    "    matching_rows = 0\n",
    "    different_rows = 0\n",
    "    diff_list=[]\n",
    "    \n",
    "    for j in range(0,len(df.index)):\n",
    "        same = True\n",
    "        for i in column_List:\n",
    "            left_Data = i + \"_x\"\n",
    "            right_Data = i + \"_y\"\n",
    "            if(df.iloc[j][left_Data]-df.iloc[j][right_Data] != 0):\n",
    "                #print(df.iloc[j][\"Pct_std\"])\n",
    "                #print(left_Data)\n",
    "                #print(df.iloc[j][left_Data]-df.iloc[j][right_Data])\n",
    "                #print(\"\")\n",
    "                same = False\n",
    "        if(same != True):\n",
    "            different_rows +=1\n",
    "            diff_list.append(df.iloc[j][\"Pct_std\"])\n",
    "            \n",
    "        else:\n",
    "            matching_rows +=1\n",
    "    print(\"There are \", len(df.index),\" total rows\")\n",
    "    print(different_rows,\" of these rows have election result differences\")\n",
    "    print(matching_rows,\" of these rows are the same\")\n",
    "    print(diff_list)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  4611  total rows\n",
      "24  of these rows have election result differences\n",
      "4587  of these rows are the same\n",
      "['MON0008', 'MON0009', 'MON0010', 'MON0011', 'MON0012', 'MON0013', 'MON0014', 'MON0015', 'MON0016', 'MON0017', 'MON0018', 'MON0019', 'MON0020', 'MON0021', 'MON0022', 'MON0023', 'MON0024', 'MON0025', 'MON0028', 'MON0029', 'MON0030', 'MON0031', 'MON0032', 'WAS0012']\n",
      "\n",
      "There are  1271  total rows\n",
      "0  of these rows have election result differences\n",
      "1271  of these rows are the same\n",
      "[]\n",
      "\n",
      "There are  101  total rows\n",
      "1  of these rows have election result differences\n",
      "100  of these rows are the same\n",
      "['WAS0011']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "column_List = ['G18A10NO','G18A10YES','G18A11NO','G18A11YES','G18A12NO','G18A12YES','G18A13NO','G18A13YES','G18A01NO','G18A01YES',\n",
    "                      'G18A02NO','G18A02YES', 'G18A03NO','G18A03YES','G18A04NO','G18A04YES','G18A05NO','G18A05YES',\n",
    "                      'G18A06NO', 'G18A06YES','G18A07NO', 'G18A07YES','G18A09NO','G18A09YES',\n",
    "                      'G18ATGRMOO', 'G18ATGOSIS','G18ATGDSHA','G18CFODRIN','G18CFORPAT', 'G18AGRRCAL','G18AGRDFRI', \n",
    "                       'G18GOVRDES','G18GOVONPA','G18GOVDGIL','G18GOVORIC','G18USSDNEL','G18USSRSCO']\n",
    "\n",
    "validater_row(merged_data_everything[(merged_data_everything[\"main_merge\"]==\"both\") & (merged_data_everything[\"_merge\"]==\"both\")],column_List)  \n",
    "validater_row(merged_data_everything[(merged_data_everything[\"main_merge\"]==\"both\") & (merged_data_everything[\"_merge\"]==\"No shapefile available\")],column_List) \n",
    "validater_row(merged_data_everything[(merged_data_everything[\"main_merge\"]==\"both\") & (merged_data_everything[\"_merge\"]==\"left_only\")],column_List) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing Geometries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_list = ['MON0008', 'MON0009', 'MON0010', 'MON0011', 'MON0012', 'MON0013', 'MON0014', 'MON0015', 'MON0016', 'MON0017', 'MON0018', 'MON0019', 'MON0020', 'MON0021', 'MON0022', 'MON0023', 'MON0024', 'MON0025', 'MON0028', 'MON0029', 'MON0030', 'MON0031', 'MON0032', 'WAS0011', 'WAS0012']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_data = vtds_2018_election[vtds_2018_election[\"_merge\"]==\"both\"]\n",
    "print(matched_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precincts that only appear in the VEST file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(vest_vtds.value_counts())\n",
    "\n",
    "#There appear to be 67 'PAL00NP' precincts and 23 others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at the \"PAL00NP\"\n",
    "display.max_columns=True\n",
    "\n",
    "#These all look to be 0\n",
    "display(vest_fl[vest_fl['Pct_std']==\"PAL00NP\"])\n",
    "sum(vest_fl[vest_fl['Pct_std']==\"PAL00NP\"][\"G18GOVDGIL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_precncts = [\"PAL00NP\",\"PASGULF\",\"BRE0000\",\"FLA0998\",\"LEO1201\",\"LEO1213\",\"LEO1231\",\"LEO1304\",\"LEO3402\",\"LEO4111\",\"LEO4115\",\"LEO5113\"]\n",
    "print(vtds_2018_election[(vtds_2018_election[\"_merge\"]==\"right_only\")&(~vtds_2018_election[\"Pct_std\"].isin(empty_precncts))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vtds_2018_election[vtds_2018_election[\"_merge\"]==\"right_only\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_precncts=[\"FLA0099\",\"PAL8001\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precincts that only appear in the FL source file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fl_official_vtds.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vtds_2018_election[vtds_2018_election[\"_merge\"]==\"left_only\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_precncts=[\"FLA0099\",\"PAL8001\"]\n",
    "print(vtds_2018_election[(vtds_2018_election[\"_merge\"]==\"left_only\")&(~vtds_2018_election[\"Pct_std\"].isin(empty_precncts))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEM00EV may need to be parceled out\n",
    "others = {\"CAL0201\":\"CAL201/201C\",\"MON0033\":\"MON0041\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(fl_official_vtds[fl_official_vtds['Pct_std']==\"MON0036\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(vest_fl[vest_fl['Pct_std']==\"MON0006\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.max_columns=True\n",
    "display(vest_fl[vest_fl['Pct_std']==\"PAL00NP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest_fl[vest_fl['Pct_std']==\"PAL00NP\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matched_data[matched_data[\"Pct_std\"]==\"DAD0011\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
