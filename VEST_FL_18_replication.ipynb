{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import maup # mggg's library for proration, see documentation here: https://github.com/mggg/maup\n",
    "import pandas as pd # standard python data library\n",
    "import geopandas as gp # the geo-version of pandas\n",
    "import numpy as np \n",
    "import os\n",
    "import fiona\n",
    "from statistics import mean, median\n",
    "from pandas import read_csv\n",
    "gp.io.file.fiona.drvsupport.supported_drivers['KML'] = 'rw' #To load KML files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Precinct-level Elections Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This Data is from the FL department of state, and can only be downloaded county by county\n",
    "all_files = os.listdir(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/precinctlevelelectionresults2018gen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that all files have the same number of columns\n",
    "for i in all_files:\n",
    "    ref = \"./precinctlevelelectionresults2018gen/\"\n",
    "    file_ref = ref+i\n",
    "    file_prev = pd.read_csv(file_ref,sep=\"\\t\",engine='python',index_col=None, header=None)\n",
    "    print(file_prev.shape)\n",
    "    \n",
    "#All the files have 19 columns, so they should be good to combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(743093, 19)\n"
     ]
    }
   ],
   "source": [
    "#Create a dataframe with the txt files\n",
    "li = []\n",
    "for i in all_files:\n",
    "    ref = \"./precinctlevelelectionresults2018gen/\"\n",
    "    file_ref = ref+i\n",
    "    file_prev = pd.read_csv(file_ref,sep=\"\\t\",engine='python',index_col=None, header=None)\n",
    "    li.append(file_prev)\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "print(frame.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to data definitions and field codes  \n",
    "https://fldoswebumbracoprod.blob.core.windows.net/media/694099/precinct-level-results-data-definition-field-codes.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0       1      2           3                      4  5              6   \\\n",
      "0  HOL  Holmes  10481  11/06/2018  2018 General Election  1  Ponce de Leon   \n",
      "1  HOL  Holmes  10481  11/06/2018  2018 General Election  1  Ponce de Leon   \n",
      "2  HOL  Holmes  10481  11/06/2018  2018 General Election  1  Ponce de Leon   \n",
      "3  HOL  Holmes  10481  11/06/2018  2018 General Election  1  Ponce de Leon   \n",
      "4  HOL  Holmes  10481  11/06/2018  2018 General Election  1  Ponce de Leon   \n",
      "\n",
      "     7   8   9   10                     11 12      13            14   15  \\\n",
      "0  1152   0   0   0  United States Senator     120000    Rick Scott  REP   \n",
      "1  1152   0   0   0  United States Senator     120000   Bill Nelson  DEM   \n",
      "2  1152   0   0   0  United States Senator     120000  WriteinVotes        \n",
      "3  1152   0   0   0  United States Senator     120000     OverVotes        \n",
      "4  1152   0   0   0  United States Senator     120000    UnderVotes        \n",
      "\n",
      "          16     17   18  \n",
      "0  103093132  71039  601  \n",
      "1  113049868  70482   97  \n",
      "2          0    900    3  \n",
      "3          0    901    0  \n",
      "4          0    902    7  \n"
     ]
    }
   ],
   "source": [
    "print(frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter down to the relevant races\n",
    "office_List = ['United States Senator','Governor','Attorney General','Chief Financial Officer','Commissioner of Agriculture','Amendment No. 1: Increased Homestead Property Tax Exemption','Amendment No. 2: Limitations on Property Tax Assessments','Amendment No. 3: Voter Control of Gambling in Florida','Amendment No. 4: Voting Restoration Amendment','Amendment No. 5: Supermajority Vote Required to Impose, Authorize, or Raise State Taxes or Fees','Amendment No. 6: Rights of Crime Victims; Judges','Amendment No. 7: First Responder and Military Member Survivor Benefits; Public Colleges and Universities','Amendment No. 9: Prohibits Offshore Oil and Gas Drilling; Prohibits Vaping in Enclosed Indoor Workplaces','Amendment No. 10: State and Local Government Structure and Operation','Amendment No. 11: Property Rights; Removal of Obsolete Provision; Criminal Statutes','Amendment No. 12: Lobbying and Abuse of Office by Public Officers','Amendment No. 13: Ends Dog Racing']\n",
    "filtered_frame=frame[frame[11].isin(office_List)]\n",
    "\n",
    "#Filter out unused columns\n",
    "filtered_frame = filtered_frame.drop(columns=[1,2,3,4,8,9,10,12,13],axis=1)\n",
    "\n",
    "#Filter out Senator WriteinVotes and OverVotes and UnderVotes\n",
    "no_count = ['WriteinVotes','OverVotes','UnderVotes']\n",
    "filtered_frame = filtered_frame[~filtered_frame[14].isin(no_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the precinct column at least 4 digits\n",
    "filtered_frame[5]=filtered_frame[5].astype(str)\n",
    "filtered_frame[\"modified_pre\"]=filtered_frame[5].str.zfill(4)\n",
    "\n",
    "#Make a column with the 3 letter county code and the precincts\n",
    "filtered_frame[\"Pct_std\"]=filtered_frame[0]+filtered_frame[\"modified_pre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivot the data so that each row has all the results from that precinct\n",
    "pivoted_2018 = pd.pivot_table(filtered_frame, values=[18], index=[\"Pct_std\"],columns=[11,14],aggfunc=sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up index\n",
    "pivoted_2018 = pivoted_2018.reset_index()\n",
    "pd.set_option('display.max_columns', None)\n",
    "#display(pivoted_2018)\n",
    "\n",
    "#Rename the columns\n",
    "pivoted_2018.columns=['Pct_std','G18A10NO','G18A10YES','G18A11NO','G18A11YES','G18A12NO','G18A12YES','G18A13NO','G18A13YES','G18A01NO','G18A01YES',\n",
    "                      'G18A02NO','G18A02YES', 'G18A03NO','G18A03YES','G18A04NO','G18A04YES','G18A05NO','G18A05YES',\n",
    "                      'G18A06NO', 'G18A06YES','G18A07NO', 'G18A07YES','G18A09NO','G18A09YES',\n",
    "                      'G18ATGRMOO', 'G18ATGOSIS','G18ATGDSHA','G18CFODRIN','G18CFORPAT', 'G18AGRRCAL','G18AGRDFRI', \n",
    "                       'G18GOVRDES','G18GOV_to_add1','G18GOV_to_add2','G18GOVDGIL','G18GOVORIC','G18GOV_to_add3','G18USSDNEL','G18USSRSCO']\n",
    "\n",
    "#Fix governors results (they count all the no party candidates together)\n",
    "pivoted_2018['G18GOVONPA']=pivoted_2018['G18GOV_to_add1']+pivoted_2018['G18GOV_to_add2']+pivoted_2018['G18GOV_to_add3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pct_std  G18A10NO  G18A10YES  G18A11NO  G18A11YES  G18A12NO  G18A12YES  \\\n",
      "0  ALA0001     367.0      500.0     421.0      434.0     254.0      613.0   \n",
      "1  ALA0002     563.0      743.0     619.0      667.0     449.0      879.0   \n",
      "2  ALA0003    1096.0     1476.0    1161.0     1348.0     730.0     1884.0   \n",
      "3  ALA0004     811.0     1169.0     893.0     1068.0     618.0     1392.0   \n",
      "4  ALA0005    1178.0      631.0     888.0      906.0     671.0     1181.0   \n",
      "\n",
      "   G18A13NO  G18A13YES  G18A01NO  G18A01YES  G18A02NO  G18A02YES  G18A03NO  \\\n",
      "0     414.0      476.0     420.0      464.0     357.0      512.0     236.0   \n",
      "1     600.0      748.0     651.0      702.0     571.0      760.0     346.0   \n",
      "2    1013.0     1640.0    1141.0     1525.0     988.0     1625.0     731.0   \n",
      "3     962.0     1081.0     799.0     1244.0     643.0     1382.0     635.0   \n",
      "4     383.0     1554.0    1313.0      562.0    1138.0      708.0     505.0   \n",
      "\n",
      "   G18A03YES  G18A04NO  G18A04YES  G18A05NO  G18A05YES  G18A06NO  G18A06YES  \\\n",
      "0      659.0     375.0      526.0     301.0      576.0     386.0      502.0   \n",
      "1     1015.0     551.0      816.0     531.0      806.0     634.0      708.0   \n",
      "2     1939.0    1134.0     1539.0     941.0     1692.0    1255.0     1383.0   \n",
      "3     1416.0     975.0     1077.0     627.0     1403.0     908.0     1115.0   \n",
      "4     1405.0     313.0     1642.0    1199.0      681.0    1251.0      616.0   \n",
      "\n",
      "   G18A07NO  G18A07YES  G18A09NO  G18A09YES  G18ATGRMOO  G18ATGOSIS  \\\n",
      "0     387.0      490.0     358.0      529.0       563.0        17.0   \n",
      "1     600.0      747.0     552.0      799.0       762.0        32.0   \n",
      "2    1072.0     1557.0    1021.0     1616.0      1646.0        42.0   \n",
      "3     813.0     1216.0     897.0     1124.0      1408.0        24.0   \n",
      "4    1117.0      758.0     384.0     1543.0       483.0        38.0   \n",
      "\n",
      "   G18ATGDSHA  G18CFODRIN  G18CFORPAT  G18AGRRCAL  G18AGRDFRI  G18GOVRDES  \\\n",
      "0       323.0       348.0       539.0       545.0       347.0       544.0   \n",
      "1       584.0       617.0       740.0       740.0       622.0       739.0   \n",
      "2      1022.0      1102.0      1563.0      1592.0      1100.0      1592.0   \n",
      "3       629.0       677.0      1358.0      1356.0       687.0      1372.0   \n",
      "4      1412.0      1397.0       509.0       448.0      1471.0       438.0   \n",
      "\n",
      "   G18GOV_to_add1  G18GOV_to_add2  G18GOVDGIL  G18GOVORIC  G18GOV_to_add3  \\\n",
      "0             3.0             4.0       357.0         2.0             0.0   \n",
      "1             1.0             4.0       622.0        12.0             8.0   \n",
      "2             4.0             8.0      1123.0        13.0             4.0   \n",
      "3             6.0             7.0       688.0         8.0             4.0   \n",
      "4             2.0             5.0      1525.0         7.0             4.0   \n",
      "\n",
      "   G18USSDNEL  G18USSRSCO  G18GOVONPA County  \n",
      "0       372.0       532.0         7.0    ALA  \n",
      "1       662.0       717.0        13.0    ALA  \n",
      "2      1192.0      1541.0        16.0    ALA  \n",
      "3       767.0      1320.0        17.0    ALA  \n",
      "4      1545.0       433.0        11.0    ALA  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5999, 42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recreate the county code\n",
    "pivoted_2018[\"County\"]=pivoted_2018[\"Pct_std\"].str[0:3]\n",
    "\n",
    "#Check how it looks\n",
    "print(pivoted_2018.head())\n",
    "pivoted_2018.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all there are 5,999 rows in the precinct election results dataframe. The next step is to merge these precincts with the shapefiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Shapefiles**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation mentions 4 different sources for the shapefiles:\n",
    "\n",
    "1) Florida department of state (16 counties)  \n",
    "2) 2016 VEST shapefile (17 counties)  \n",
    "3) U.S. Census Bureau's 2020 Redistricting Data Program Phase 2 release (18 counties)  \n",
    "4) Counties (14 counties)  \n",
    "\n",
    "67 total counties in FL, sources for 65 listed here.  \n",
    "\n",
    "2 remaining counties are:  Columbia, Duval  \n",
    "\n",
    "From an email conversation w/ Brian Amos (brianamos@gmail.com) on 01/13/21, I learned that:  \n",
    "    \"Columbia and Duval were sent from their respective SOE offices\"  \n",
    "    \"FL DOS shapefiles were a records request\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resource for this: county names and three letter codes sheet   \n",
    "  \n",
    "['HOL' 'LEV' 'STL' 'HAR' 'CAL' 'ALA' 'HER' 'WAK' 'MON' 'POL' 'OSC' 'JAC'\n",
    " 'WAL' 'DES' 'PAS' 'DIX' 'JEF' 'MRN' 'GIL' 'TAY' 'GAD' 'SUW' 'STJ' 'SEM'\n",
    " 'BAK' 'SAN' 'OKA' 'PAL' 'SAR' 'BRO' 'BRE' 'CIT' 'GUL' 'HIG' 'MAN' 'IND'\n",
    " 'MAD' 'PIN' 'LEO' 'LEE' 'NAS' 'FLA' 'OKE' 'CLM' 'LAK' 'UNI' 'BRA' 'DUV'\n",
    " 'LAF' 'BAY' 'FRA' 'CLA' 'ORA' 'SUM' 'LIB' 'HAM' 'GLA' 'PUT' 'CLL' 'HEN'\n",
    " 'MRT' 'DAD' 'HIL' 'VOL' 'CHA' 'ESC' 'WAS']\n",
    "['Holmes' 'Levy' 'St. Lucie' 'Hardee' 'Calhoun' 'Alachua' 'Hernando'\n",
    " 'Wakulla' 'Monroe' 'Polk' 'Osceola' 'Jackson' 'Walton' 'Desoto' 'Pasco'\n",
    " 'Dixie' 'Jefferson' 'Marion' 'Gilchrist' 'Taylor' 'Gadsden' 'Suwannee'\n",
    " 'St. Johns' 'Seminole' 'Baker' 'Santa Rosa' 'Okaloosa' 'Palm Beach'\n",
    " 'Sarasota' 'Broward' 'Brevard' 'Citrus' 'Gulf' 'Highlands' 'Manatee'\n",
    " 'Indian River' 'Madison' 'Pinellas' 'Leon' 'Lee' 'Nassau' 'Flagler'\n",
    " 'Okeechobee' 'Columbia' 'Lake' 'Union' 'Bradford' 'Duval' 'Lafayette'\n",
    " 'Bay' 'Franklin' 'Clay' 'Orange' 'Sumter' 'Liberty' 'Hamilton' 'Glades'\n",
    " 'Putnam' 'Collier' 'Hendry' 'Martin' 'Miami-Dade' 'Hillsborough'\n",
    " 'Volusia' 'Charlotte' 'Escambia' 'Washington']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Florida Department of State (16 counties)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quote from the README\n",
    "\n",
    "> \"Alachua, Baker, Bay, Bradford, Brevard, Calhoun, Citrus, Clay, Dixie, Escambia, Hardee, Hendry, Hernando, Indian River, Lafayette and Sarasota come from the Department of State.\"\n",
    "\n",
    "Note: As mentioned above, these were received by VEST via a records request. Peter called an employee (850-688-2433) of the DOS a few times, the last time being January 15th, 2021 to ask about a precinct shapefile. The FL DOS is sending a CD over with all of its precinct related archive data. At the time of writing, we have not yet recieved the files from the FL DOS.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. VEST '16 (17 counties)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quote from the README:\n",
    "\n",
    "> \"Broward, Desoto, Gadsden, Gilchrist, Gulf, Manatee, Marion, Martin, Monroe, Nassau, Pinellas, Polk, Putnam, Santa Rosa, St. Johns, St. Lucie, and Union are unchanged from the 2016 VEST shapefile.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest_16 = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/fl_2016/fl_2016.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pct county countypct  G16PRERTru  G16PREDCli  G16PRELJon  G16PRECCas  \\\n",
      "0  001    DAD    DAD001         277         195           4           0   \n",
      "1  010    DAD    DAD010          20          16           0           0   \n",
      "2  100    DAD    DAD100         641        2893          66          17   \n",
      "3  101    DAD    DAD101         679        1096          34           0   \n",
      "4  102    DAD    DAD102        1100        1596          29           1   \n",
      "\n",
      "   G16PREGSte  G16PREIDeL  G16PREoth  G16USSRRub  G16USSDMur  G16USSLSta  \\\n",
      "0           2           0          5         337         133           3   \n",
      "1           0           0          0          30           6           0   \n",
      "2          41          16         24         897        2434          50   \n",
      "3           7           0         18         845         947          14   \n",
      "4           4           2         22        1399        1274          16   \n",
      "\n",
      "   G16USSOth                                           geometry  \n",
      "0          5  POLYGON Z ((943790.734 591023.581 0.000, 94364...  \n",
      "1          0  POLYGON Z ((942137.421 562243.019 0.000, 94093...  \n",
      "2         99  POLYGON Z ((873353.097 533771.394 0.000, 87420...  \n",
      "3         17  POLYGON Z ((936263.331 593379.375 0.000, 93560...  \n",
      "4         32  POLYGON Z ((940693.858 597222.143 0.000, 94069...  \n",
      "['DAD' 'VOL' 'UNI' 'SAR' 'SAN' 'PUT' 'POL' 'PIN' 'PAL' 'OSC' 'ORA' 'MRN'\n",
      " 'LEO' 'LEE' 'LAK' 'HIL' 'HIG' 'DES' 'CAL' 'BRE' 'ALA' 'BAK' 'BAY' 'BRA'\n",
      " 'BRO' 'CIT' 'CLA' 'CLL' 'DIX' 'DUV' 'ESC' 'FLA' 'FRA' 'GAD' 'GIL' 'GLA'\n",
      " 'GUL' 'HAM' 'HAR' 'IND' 'LAF' 'LIB' 'MAN' 'MRT' 'MON' 'NAS' 'OKA' 'OKE'\n",
      " 'PAS' 'SEM' 'STJ' 'STL' 'SUM' 'SUW' 'TAY' 'WAK' 'WAS' 'JEF' 'CLM' 'CHA'\n",
      " 'JAC' 'HEN' 'LEV' 'HER' 'MAD' 'WAL' 'HOL']\n",
      "      pct county countypct                                           geometry  \\\n",
      "908  001A    UNI    UNI 1A  POLYGON Z ((234533.388 2067718.870 0.000, 2345...   \n",
      "909  001B    UNI    UNI 1B  POLYGON Z ((250790.618 2113766.930 0.000, 2508...   \n",
      "910  002A    UNI   UNI  2A  POLYGON Z ((267244.669 2086000.346 0.000, 2662...   \n",
      "911  002B    UNI   UNI  2B  POLYGON Z ((255460.267 2067684.326 0.000, 2555...   \n",
      "912  003A    UNI    UNI 3A  MULTIPOLYGON Z (((205086.233 2033920.141 0.000...   \n",
      "\n",
      "     Pct_std  \n",
      "908  UNI001A  \n",
      "909  UNI001B  \n",
      "910  UNI002A  \n",
      "911  UNI002B  \n",
      "912  UNI003A  \n"
     ]
    }
   ],
   "source": [
    "#Take a look at the file\n",
    "print(vest_16.head())\n",
    "\n",
    "#Look at the unique county\n",
    "print(vest_16[\"county\"].unique())\n",
    "\n",
    "#Make a list of relevant counties to pull\n",
    "vest_2016_counties = ['BRO','DES','GAD','GIL','GUL','MAN','MRN','MRT','MON','NAS','PIN','POL','PUT',\n",
    "                     'SAN','STJ','STL','UNI']\n",
    "\n",
    "#Filter down to the relevant counties\n",
    "shapefiles_vest_16=vest_16[vest_16['county'].isin(vest_2016_counties)]\n",
    "\n",
    "#Pull the relevant columns\n",
    "shapefiles_vest_16=shapefiles_vest_16[['pct','county','countypct','geometry']]\n",
    "\n",
    "#Modify the pct column so that it contains at least 4 characters\n",
    "shapefiles_vest_16[\"pct\"]=shapefiles_vest_16[\"pct\"].astype(str).str.zfill(4)\n",
    "\n",
    "#Create a new unique identifier column\n",
    "shapefiles_vest_16[\"Pct_std\"]=shapefiles_vest_16[\"county\"]+shapefiles_vest_16[\"pct\"]\n",
    "\n",
    "#Take a look at the new, modified file\n",
    "print(shapefiles_vest_16.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pct_std  G18A10NO  G18A10YES  G18A11NO  G18A11YES  G18A12NO  G18A12YES  \\\n",
      "304  BROA001    1204.0     1366.0     922.0     1607.0     341.0     2262.0   \n",
      "305  BROA002     288.0      422.0     248.0      451.0     120.0      585.0   \n",
      "306  BROA003     341.0      649.0     326.0      641.0     167.0      824.0   \n",
      "307  BROA004     300.0      464.0     290.0      473.0     168.0      618.0   \n",
      "308  BROA005     342.0      570.0     321.0      583.0     114.0      824.0   \n",
      "\n",
      "     G18A13NO  G18A13YES  G18A01NO  G18A01YES  G18A02NO  G18A02YES  G18A03NO  \\\n",
      "304     787.0     1855.0     837.0     1755.0     564.0     1989.0     887.0   \n",
      "305     174.0      550.0     277.0      417.0     189.0      506.0     219.0   \n",
      "306     222.0      785.0     439.0      531.0     279.0      674.0     263.0   \n",
      "307     184.0      612.0     352.0      423.0     255.0      503.0     236.0   \n",
      "308     239.0      725.0     299.0      622.0     228.0      679.0     259.0   \n",
      "\n",
      "     G18A03YES  G18A04NO  G18A04YES  G18A05NO  G18A05YES  G18A06NO  G18A06YES  \\\n",
      "304     1792.0    1177.0     1505.0     844.0     1815.0     972.0     1625.0   \n",
      "305      515.0     247.0      483.0     240.0      481.0     263.0      447.0   \n",
      "306      798.0     340.0      698.0     353.0      667.0     324.0      670.0   \n",
      "307      572.0     271.0      539.0     278.0      524.0     270.0      507.0   \n",
      "308      724.0     397.0      577.0     293.0      671.0     335.0      615.0   \n",
      "\n",
      "     G18A07NO  G18A07YES  G18A09NO  G18A09YES  G18ATGRMOO  G18ATGOSIS  \\\n",
      "304     947.0     1647.0     630.0     1973.0      1575.0        45.0   \n",
      "305     223.0      482.0     159.0      551.0       313.0        13.0   \n",
      "306     297.0      673.0     227.0      749.0       524.0        12.0   \n",
      "307     263.0      501.0     176.0      596.0       345.0        11.0   \n",
      "308     304.0      639.0     226.0      723.0       555.0        12.0   \n",
      "\n",
      "     G18ATGDSHA  G18CFODRIN  G18CFORPAT  G18AGRRCAL  G18AGRDFRI  G18GOVRDES  \\\n",
      "304      1094.0      1091.0      1601.0      1541.0      1159.0      1615.0   \n",
      "305       430.0       433.0       318.0       311.0       442.0       311.0   \n",
      "306       629.0       636.0       519.0       521.0       628.0       552.0   \n",
      "307       496.0       503.0       346.0       342.0       504.0       353.0   \n",
      "308       454.0       454.0       557.0       546.0       468.0       566.0   \n",
      "\n",
      "     G18GOV_to_add1  G18GOV_to_add2  G18GOVDGIL  G18GOVORIC  G18GOV_to_add3  \\\n",
      "304             4.0             8.0      1118.0         7.0             2.0   \n",
      "305             2.0             3.0       441.0         3.0             1.0   \n",
      "306             2.0             2.0       622.0         6.0             1.0   \n",
      "307             0.0             0.0       512.0         3.0             0.0   \n",
      "308             1.0             1.0       467.0         2.0             0.0   \n",
      "\n",
      "     G18USSDNEL  G18USSRSCO  G18GOVONPA County  \n",
      "304      1165.0      1465.0        14.0    BRO  \n",
      "305       427.0       312.0         6.0    BRO  \n",
      "306       583.0       492.0         5.0    BRO  \n",
      "307       501.0       320.0         0.0    BRO  \n",
      "308       444.0       530.0         2.0    BRO  \n"
     ]
    }
   ],
   "source": [
    "#Filter down the 2018 election results to the relevant counties where shapefiles are from VEST '16\n",
    "#(These are the only ones with a chance of matching)\n",
    "elections_vest16_counties = pivoted_2018[pivoted_2018['County'].isin(vest_2016_counties)]\n",
    "\n",
    "#See what it looks like\n",
    "print(elections_vest16_counties.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11 precincts that only appear in the vest_18\n",
      "There are 15 precincts that only appear in the vest_16\n",
      "There are 1561 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Merge shapefile with the election results\n",
    "merged_data_vest16 = pd.merge(elections_vest16_counties,shapefiles_vest_16,on=['Pct_std'],how='outer',indicator=True)\n",
    "vest_16_elections_only = merged_data_vest16[merged_data_vest16[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "vest_16_shapefile_only = merged_data_vest16[merged_data_vest16[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "vest_16_both = merged_data_vest16[merged_data_vest16[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "print(\"There are \" + str(vest_16_elections_only.count()) + \" precincts that only appear in the vest_18\")\n",
    "print(\"There are \" + str(vest_16_shapefile_only.count()) + \" precincts that only appear in the vest_16\")\n",
    "print(\"There are \" + str(vest_16_both.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(SKIP FOR NOW) Look at the shapefile**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest_fl_filtered=vest_16[vest_16['county'].isin(vest_2016_counties)]\n",
    "filtered_2016_geom[\"geometry\"]=filtered_2016_geom.buffer(0)\n",
    "vest_fl_filtered[\"geometry\"]=vest_fl_filtered.buffer(0)\n",
    "proj = vest_fl_filtered.crs\n",
    "filtered_2016_geom = filtered_2016_geom.to_crs(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(filtered_2016_geom.head())\n",
    "filtered_2016_geom.plot()\n",
    "print(filtered_2016_geom[\"county\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest_fl_filtered.plot()\n",
    "print(vest_fl_filtered[\"county\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = vest_fl_filtered.geom_almost_equals(filtered_2016_geom,decimal=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diff.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Census Redistricting Data Program (18 counties)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quote from the README:\n",
    "\n",
    "> \"Charlotte, Franklin, Glades, Hamilton, Holmes, Jackson, Jefferson, Levy, Liberty, Madison, Okeechobee, Orange, Seminole, Suwannee, Taylor, Wakulla, Walton, and Washinton come from the U.S. Census Bureau's 2020 Redistricting Data Program Phase 2 release.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When downloading from the Census redistricing data program, these use a FIPS code to identify counties\n",
    "\n",
    "fips_codes = [\"12015\",\"12037\",\"12043\",\"12047\",\"12059\",\"12063\",\"12065\",\"12075\",\"12077\",\"12079\",\"12093\",\n",
    "        \"12095\",\"12117\",\"12121\",\"12123\",\"12129\",\"12131\",\"12133\"]\n",
    "\n",
    "#Combine all the data from separate files into one\n",
    "li = []\n",
    "for i in fips_codes:\n",
    "    ref = \"./census/state_files/partnership_shapefiles_19v2_\"\n",
    "    file_ref = ref+i+\"/PVS_19_v2_vtd_\"+i+\".shp\"\n",
    "    file_prev = gp.read_file(file_ref)\n",
    "    li.append(file_prev)\n",
    "shapefiles_census = pd.concat(li, axis=0, ignore_index=True)\n",
    "#print(shapefiles_census.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  STATEFP COUNTYFP   VTDST            NAMELSAD VTDI LSAD CHNG_TYPE ORIG_NAME  \\\n",
      "0      12      015  000001   1-Voting District    A   00      None      None   \n",
      "1      12      015  000002   2-Voting District    A   00      None      None   \n",
      "2      12      015  000003   3-Voting District    A   00      None      None   \n",
      "3      12      015  000004   4-Voting District    A   00      None      None   \n",
      "4      12      015  000016  13-Voting District    A   00      None      None   \n",
      "\n",
      "  ORIG_CODE RELATE                NAME VINTAGE FUNCSTAT JUSTIFY  MTFCC  \\\n",
      "0      None   None   1-Voting District      90        N    None  G5240   \n",
      "1      None   None   2-Voting District      90        N    None  G5240   \n",
      "2      None   None   3-Voting District      90        N    None  G5240   \n",
      "3      None   None   4-Voting District      90        N    None  G5240   \n",
      "4      None   None  13-Voting District      90        N    None  G5240   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON Z ((-82.01288 26.96949 0.00000, -82.01...  \n",
      "1  POLYGON Z ((-82.02727 26.93930 0.00000, -82.02...  \n",
      "2  POLYGON Z ((-82.05635 26.94428 0.00000, -82.05...  \n",
      "3  POLYGON Z ((-82.07056 26.93519 0.00000, -82.06...  \n",
      "4  POLYGON Z ((-82.01888 26.94075 0.00000, -82.01...  \n"
     ]
    }
   ],
   "source": [
    "#Look at the data\n",
    "print(shapefiles_census.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a dictionary to convert from FIPS identifier to the 3 character county name\n",
    "county_code = {'015':\"CHA\", '037':\"FRA\", '043':\"GLA\", '047':\"HAM\", '059':\"HOL\", '063':\"JAC\", '065':\"JEF\", \n",
    "               '075':\"LEV\", '077':\"LIB\", '079':\"MAD\", '093':\"OKE\", '095':\"ORA\",\n",
    " '117':\"SEM\", '121':\"SUW\", '123':\"TAY\", '129':\"WAK\", '131':\"WAL\", '133':\"WAS\"}\n",
    "\n",
    "#Create a column with this 3-character county name\n",
    "shapefiles_census['county_name'] = shapefiles_census['COUNTYFP'].map(county_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using \"VTDST\" as the matcher, the outcome was:\n",
    "\n",
    ">There are 97 precincts that only appear in the election results  \n",
    "There are 190 precincts that only appear in the shapefile  \n",
    "There are 483 precincts that were matched between the two files  \n",
    "\n",
    "When using the first two digits of \"NAMELSAD\" as the matcher, the outcome was:\n",
    "\n",
    ">There are 281 precincts that only appear in the election results  \n",
    "There are 374 precincts that only appear in the shapefile  \n",
    "There are 299 precincts that were matched between the two files  \n",
    "\n",
    "Leads me to believe that \"VTDST\" is the better column to match on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORA440D    1\n",
      "ORA0507    1\n",
      "OKEP-01    1\n",
      "HAM0007    1\n",
      "ORA0413    1\n",
      "          ..\n",
      "HOL0004    1\n",
      "WAS0004    1\n",
      "ORA440A    1\n",
      "ORA342B    1\n",
      "CHA0057    1\n",
      "Name: Pct_std, Length: 673, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Create a unique identifier, looks like \"VTDST\" is the best column to use for this, see above\n",
    "\n",
    "#Work on the \"NAMELSAD\" column to just store this as well\n",
    "shapefiles_census[\"NAMELSAD\"]= shapefiles_census[\"NAMELSAD\"].str.split(\"-\", n = 1, expand = True)\n",
    "\n",
    "#Take off the leading zero\n",
    "shapefiles_census[\"VTDST\"] = shapefiles_census[\"VTDST\"].str.lstrip('0')\n",
    "\n",
    "#Make sure they are all at least four digits\n",
    "shapefiles_census[\"VTDST\"] = shapefiles_census[\"VTDST\"].str.zfill(4)\n",
    "shapefiles_census[\"NAMELSAD\"] = shapefiles_census[\"NAMELSAD\"].str.zfill(4)\n",
    "\n",
    "#Create the unique identifier\n",
    "shapefiles_census[\"Pct_std\"]=shapefiles_census[\"county_name\"]+shapefiles_census[\"VTDST\"]\n",
    "shapefiles_census[\"alt_Pct_std\"]=shapefiles_census[\"county_name\"]+shapefiles_census[\"NAMELSAD\"]\n",
    "\n",
    "#Confirm that the unique identifier really is unique\n",
    "print(shapefiles_census[\"Pct_std\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter down the 2018 election results to the relevant counties where shapefiles are from the Census Redist. Data Program\n",
    "#(These are the only ones with a chance of matching)\n",
    "census_counties = [\"CHA\",\"FRA\",\"GLA\",\"HAM\",\"HOL\",\"JAC\",\"JEF\",\"LEV\",\"LIB\",\"MAD\",\"OKE\",\"ORA\",\"SEM\",\"SUW\",\"TAY\",\"WAK\",\"WAL\",\"WAS\"]\n",
    "election_census=pivoted_2018[pivoted_2018[\"County\"].isin(census_counties)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 97 precincts that only appear in the election results\n",
      "There are 190 precincts that only appear in the shapefile\n",
      "There are 483 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Merge the shapefile with election results\n",
    "merged_data_census = pd.merge(election_census,shapefiles_census,on=['Pct_std'],how='outer',indicator=True)\n",
    "census_elections_only = merged_data_census[merged_data_census[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "census_shapefile_only = merged_data_census[merged_data_census[\"_merge\"]==\"right_only\"][['Pct_std',\"alt_Pct_std\"]]\n",
    "census_both = merged_data_census[merged_data_census[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "print(\"There are \" + str(census_elections_only.count()) + \" precincts that only appear in the election results\")\n",
    "print(\"There are \" + str(len(census_shapefile_only)) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(census_both.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export these to CSV to compare, it doesn't seem like there is a simple fix for these\n",
    "census_elections_only_export = pd.Series(census_elections_only)\n",
    "census_elections_only_export.to_csv(\"./census_elections_only.csv\")\n",
    "\n",
    "census_shapefile_only.to_csv(\"./census_shapefile_only.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Counties themselves (16 counties - 14 mentioned in old README and 2 others from convo)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quote from README:\n",
    "\n",
    ">\"Collier, Flagler, Highlands, Hillsborough, Lake, Lee, Leon, Miami-Dade, Okaloosa, Osceola, Palm Beach, Pasco, Sumter, and Volusia come from the counties.\"\n",
    "\n",
    "Quote from Brian Amos on the other 2 counties:\n",
    "\n",
    ">\"Columbia and Duval were sent from their respective SOE offices\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I was able to find:\n",
    "\n",
    "- Collier - (downloaded) https://www.colliervotes.com/Voting-System-Maps-Stats/Precinct-Map-Voting-Boundaries     \n",
    "- Flagler - (downloaded) https://www.flaglerelections.com/For-Voters/District-Precinct-Maps   \n",
    "- Highlands - (not found)  \n",
    "- Hillsborough - (downloaded) https://www.votehillsborough.org/RESEARCH-DATA/Maps-Districts   \n",
    "- Lake - (not found)  \n",
    "- Lee - (downloaded) https://www.google.com/maps/d/viewer?mid=1FjtBs8SVp4PQjLmY09QUr9z-Pks&ll=26.559040386734967%2C-82.17803191789233&z=10  \n",
    "- Leon - (downloaded) https://geodata-tlcgis.opendata.arcgis.com/datasets/election-precincts-leon-county  \n",
    "- Miami-Dade  - (downloaded) https://gis-mdc.opendata.arcgis.com/datasets/precinct-1    \n",
    "- Okaloosa  - (downloaded) http://www.co.okaloosa.fl.us/gis_data  \n",
    "- Osceola  -  (couldn't find) https://www.voteosceola.com/en-us/Candidate-Information/Map-Files  \n",
    "- Palm Beach  -  (downloaded) https://www.pbcelections.org/Records-Data/Voting-District-Maps  \n",
    "- Pasco  -  (downloaded) https://www.pascocountyfl.net/342/GIS-Data-Shape-Files  \n",
    "- Sumter  - (couldn't find)  \n",
    "- Volusia  -  (couldn't find)  \n",
    "- Columbia -  (couldn't find)   \n",
    "- Duval -  (couldn't find)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Collier, I had to load the KML into Google Earth Pro and then export it to get the precinct labels to show up\n",
    "shapefiles_collier = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/counties/Precinct Boundaries_collier.kml\")\n",
    "flagler_pcts = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/counties/Flagler (2018-02-05)/VTDBLK_1_region.shp\")\n",
    "shapefiles_hillsborough = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/counties/HillsCtyElections-Various Files-2017 Shapefiles-2021015-3a3/2017ShapeFiles/PRECINCT12057_region.shp\")\n",
    "shapefiles_lee = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/counties/Lee County Precincts.kml\",driver='KML',split=\"<br>\")\n",
    "shapefiles_leon = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/counties/Election_Precincts_-_Leon_County-shp/Election_Precincts_-_Leon_County.shp\")\n",
    "shapefiles_miami = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/counties/Miami_Precinct-shp/Precinct.shp\")\n",
    "shapefiles_okaloosa = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/counties/Okaloosa County/precinct.shp\")\n",
    "shapefiles_palm = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/counties/Palm Beach SOE Shapefiles 2021/Precincts 2021.shp\")\n",
    "shapefiles_pasco = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/counties/Pasco VotingPrecincts_12112020_202012301214529224/VotingPrecincts_12112020.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 precincts that only appear in the election results\n",
      "There are 0 precincts that only appear in the shapefile\n",
      "There are 58 precincts that were matched between the two files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-132-c3406ce01fe7>:19: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  collier_elections_only = merged_data_flagler[merged_data_collier[\"_merge\"]==\"left_only\"]['Pct_std']\n",
      "<ipython-input-132-c3406ce01fe7>:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  collier_shapefile_only = merged_data_flagler[merged_data_collier[\"_merge\"]==\"right_only\"]['Pct_std']\n"
     ]
    }
   ],
   "source": [
    "#Take a look at the file\n",
    "#print(shapefiles_collier.head())\n",
    "\n",
    "#The \"Name\" column seems like the best one to use, but needs to be cleaned\n",
    "#print(shapefiles_collier[\"Name\"])\n",
    "shapefiles_collier[\"Name\"] = shapefiles_collier[\"Name\"].str.replace('Precinct ','')\n",
    "\n",
    "#Make sure the name column has at least four characters\n",
    "shapefiles_collier[\"Name\"]= shapefiles_collier[\"Name\"].str.zfill(4)\n",
    "\n",
    "#Create the unique identifier\n",
    "shapefiles_collier[\"Pct_std\"]=\"CLL\"+shapefiles_collier[\"Name\"]\n",
    "\n",
    "#Filter down the election results\n",
    "election_collier = pivoted_2018[pivoted_2018[\"County\"]==\"CLL\"]\n",
    "\n",
    "#Merge data\n",
    "merged_data_collier = pd.merge(election_collier,shapefiles_collier,on=['Pct_std'],how='outer',indicator=True)\n",
    "collier_elections_only = merged_data_flagler[merged_data_collier[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "collier_shapefile_only = merged_data_flagler[merged_data_collier[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "collier_both = merged_data_collier[merged_data_collier[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "#Print diffrences\n",
    "print(\"There are \" + str(collier_elections_only.count()) + \" precincts that only appear in the election results\")\n",
    "print(\"There are \" + str(collier_shapefile_only.count()) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(collier_both.count()) + \" precincts that were matched between the two files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 precincts that only appear in the election results\n",
      "There are 1 precincts that only appear in the shapefile\n",
      "There are 25 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Take a look at the shapefile\n",
    "#print(flagler_pcts.head())\n",
    "#print(flagler_pcts.shape)\n",
    "\n",
    "#\"PRECINCT\" is the right column to use, but it isn't unique (needs to be grouped by this)\n",
    "#print(flagler_pcts[\"PRECINCT\"].value_counts())\n",
    "\n",
    "#Group by precinct # and reset index\n",
    "shapefiles_flagler = flagler_pcts.dissolve(by=\"PRECINCT\")\n",
    "shapefiles_flagler = shapefiles_flagler.reset_index()\n",
    "\n",
    "#Edit the precinct column to contain at least 4 character\n",
    "shapefiles_flagler[\"PRECINCT\"]= shapefiles_flagler[\"PRECINCT\"].str.zfill(4)\n",
    "\n",
    "#Create a unique identifer\n",
    "shapefiles_flagler[\"Pct_std\"]=\"FLA\"+shapefiles_flagler[\"PRECINCT\"]\n",
    "\n",
    "#Check this looks okay\n",
    "#print(shapefiles_flagler.head())\n",
    "\n",
    "#Filter down the election results\n",
    "election_flagler = pivoted_2018[pivoted_2018[\"County\"]==\"FLA\"]\n",
    "\n",
    "#Merge data\n",
    "merged_data_flagler = pd.merge(election_flagler,shapefiles_flagler,on=['Pct_std'],how='outer',indicator=True)\n",
    "flagler_elections_only = merged_data_flagler[merged_data_flagler[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "flagler_shapefile_only = merged_data_flagler[merged_data_flagler[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "flagler_both = merged_data_flagler[merged_data_flagler[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "#Print diffrences\n",
    "print(\"There are \" + str(flagler_elections_only.count()) + \" precincts that only appear in the election results\")\n",
    "print(\"There are \" + str(flagler_shapefile_only.count()) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(flagler_both.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 precincts that only appear in the election results\n",
      "There are 0 precincts that only appear in the shapefile\n",
      "There are 390 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Take a look\n",
    "#print(shapefiles_hillsborough.head())\n",
    "\n",
    "#Use the \"PRECINCT\" column\n",
    "#print(shapefiles_hillsborough[\"PRECINCT\"].shape)\n",
    "\n",
    "#Edit the precinct column to contain at least 4 character\n",
    "shapefiles_hillsborough[\"PRECINCT\"]= shapefiles_hillsborough[\"PRECINCT\"].str.zfill(4)\n",
    "\n",
    "#Create the unique identifer column\n",
    "shapefiles_hillsborough[\"Pct_std\"]=\"HIL\"+shapefiles_hillsborough[\"PRECINCT\"]\n",
    "\n",
    "#Filter down the election results\n",
    "election_hillsborough = pivoted_2018[pivoted_2018[\"County\"]==\"HIL\"]\n",
    "\n",
    "#Merge data\n",
    "merged_data_hillsborough = pd.merge(election_hillsborough,shapefiles_hillsborough,on=['Pct_std'],how='outer',indicator=True)\n",
    "hillsborough_elections_only = merged_data_hillsborough[merged_data_hillsborough[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "hillsborough_shapefile_only = merged_data_hillsborough[merged_data_hillsborough[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "hillsborough_both = merged_data_hillsborough[merged_data_hillsborough[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "#Print diffrences\n",
    "print(\"There are \" + str(hillsborough_elections_only.count()) + \" precincts that only appear in the election results\")\n",
    "print(\"There are \" + str(hillsborough_shapefile_only.count()) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(hillsborough_both.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 precincts that only appear in the election results\n",
      "There are 0 precincts that only appear in the shapefile\n",
      "There are 127 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Take a look\n",
    "#print(shapefiles_lee.head())\n",
    "\n",
    "#From examining the map, only concerned with those that don't start with \"()\", as those designate a voting place, not an entire precinct\n",
    "shapefiles_lee[\"First_char\"] = shapefiles_lee[\"Name\"].astype(str).str[0]==\"(\"\n",
    "shapefiles_lee = shapefiles_lee[shapefiles_lee[\"First_char\"]==False]\n",
    "\n",
    "#Now can use the \"Name\" column to create the unique identifier\n",
    "shapefiles_lee[\"Name\"]= shapefiles_lee[\"Name\"].str.zfill(4)\n",
    "\n",
    "#Create the unique identifer column\n",
    "shapefiles_lee[\"Pct_std\"]=\"LEE\"+shapefiles_lee[\"Name\"]\n",
    "\n",
    "#Filter down the election results\n",
    "election_lee = pivoted_2018[pivoted_2018[\"County\"]==\"LEE\"]\n",
    "\n",
    "#Merge data\n",
    "merged_data_lee = pd.merge(election_lee,shapefiles_lee,on=['Pct_std'],how='outer',indicator=True)\n",
    "lee_elections_only = merged_data_lee[merged_data_lee[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "lee_shapefile_only = merged_data_lee[merged_data_lee[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "lee_both = merged_data_lee[merged_data_lee[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "#Print diffrences\n",
    "print(\"There are \" + str(lee_elections_only.count()) + \" precincts that only appear in the election results\")\n",
    "print(\"There are \" + str(lee_shapefile_only.count()) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(lee_both.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 precincts that only appear in the election results\n",
      "There are 9 precincts that only appear in the shapefile\n",
      "There are 155 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Take a look at the file\n",
    "#print(shapefiles_leon.head())\n",
    "\n",
    "#Edit the precinct column to contain at least 4 character\n",
    "shapefiles_leon[\"PRECINCT\"]= shapefiles_leon[\"PRECINCT\"].str.zfill(4)\n",
    "\n",
    "#Create the unique identifer column\n",
    "shapefiles_leon[\"Pct_std\"]=\"LEO\"+shapefiles_leon[\"PRECINCT\"]\n",
    "\n",
    "#Filter down the election results\n",
    "election_leon = pivoted_2018[pivoted_2018[\"County\"]==\"LEO\"]\n",
    "\n",
    "#Merge data\n",
    "merged_data_leon = pd.merge(election_leon,shapefiles_leon,on=['Pct_std'],how='outer',indicator=True)\n",
    "leon_elections_only = merged_data_leon[merged_data_leon[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "leon_shapefile_only = merged_data_leon[merged_data_leon[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "leon_both = merged_data_leon[merged_data_leon[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "#Print diffrences\n",
    "print(\"There are \" + str(leon_elections_only.count()) + \" precincts that only appear in the election results\")\n",
    "print(\"There are \" + str(leon_shapefile_only.count()) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(leon_both.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 precincts that only appear in the election results\n",
      "There are 0 precincts that only appear in the shapefile\n",
      "There are 783 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Take a look, looks like \"ID\" is an okay column to use\n",
    "#print(shapefiles_miami.head())\n",
    "\n",
    "#Convert the ID column to contain at least 4 character\n",
    "shapefiles_miami[\"ID\"] = shapefiles_miami[\"ID\"].apply(str)\n",
    "shapefiles_miami[\"ID\"] = shapefiles_miami[\"ID\"].str.zfill(4)\n",
    "\n",
    "#Create the unique identifer column\n",
    "shapefiles_miami[\"Pct_std\"]=\"DAD\"+shapefiles_miami[\"ID\"]\n",
    "\n",
    "#Filter down the election results\n",
    "election_miami = pivoted_2018[pivoted_2018[\"County\"]==\"DAD\"]\n",
    "\n",
    "#Merge data\n",
    "merged_data_miami = pd.merge(election_miami,shapefiles_miami,on=['Pct_std'],how='outer',indicator=True)\n",
    "miami_elections_only = merged_data_miami[merged_data_miami[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "miami_shapefile_only = merged_data_miami[merged_data_miami[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "miami_both = merged_data_miami[merged_data_miami[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "#Print diffrences\n",
    "print(\"There are \" + str(miami_elections_only.count()) + \" precincts that only appear in the election results\")\n",
    "print(\"There are \" + str(miami_shapefile_only.count()) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(miami_both.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 precincts that only appear in the election results\n",
      "There are 0 precincts that only appear in the shapefile\n",
      "There are 52 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Take a look\n",
    "#print(shapefiles_okaloosa.head())\n",
    "\n",
    "#Looks like \"NO\" is the right column, convert to string and edit to contain at least 4 characters\n",
    "shapefiles_okaloosa[\"NO\"] = shapefiles_okaloosa[\"NO\"].apply(str)\n",
    "shapefiles_okaloosa[\"NO\"] = shapefiles_okaloosa[\"NO\"].str.zfill(4)\n",
    "\n",
    "#Create the unique identifer column\n",
    "shapefiles_okaloosa[\"Pct_std\"]=\"OKA\"+shapefiles_okaloosa[\"NO\"]\n",
    "\n",
    "#Filter down the election results\n",
    "election_okaloosa = pivoted_2018[pivoted_2018[\"County\"]==\"OKA\"]\n",
    "\n",
    "#Merge data\n",
    "merged_data_okaloosa = pd.merge(election_okaloosa,shapefiles_okaloosa,on=['Pct_std'],how='outer',indicator=True)\n",
    "okaloosa_elections_only = merged_data_okaloosa[merged_data_okaloosa[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "okaloosa_shapefile_only = merged_data_okaloosa[merged_data_okaloosa[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "okaloosa_both = merged_data_okaloosa[merged_data_okaloosa[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "#Print diffrences\n",
    "print(\"There are \" + str(okaloosa_elections_only.count()) + \" precincts that only appear in the election results\")\n",
    "print(\"There are \" + str(okaloosa_shapefile_only.count()) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(okaloosa_both.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 precincts that only appear in the election results\n",
      "There are 4 precincts that only appear in the shapefile\n",
      "There are 868 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Take a look, looks like \"PRECINCT\" is the column to use\n",
    "#print(shapefiles_palm.head())\n",
    "\n",
    "#Edit the precinct column to contain at least 4 character\n",
    "shapefiles_palm[\"PRECINCT\"]= shapefiles_palm[\"PRECINCT\"].str.zfill(4)\n",
    "\n",
    "#Create the unique identifer column\n",
    "shapefiles_palm[\"Pct_std\"]=\"PAL\"+shapefiles_palm[\"PRECINCT\"]\n",
    "\n",
    "#Filter down the election results\n",
    "election_palm = pivoted_2018[pivoted_2018[\"County\"]==\"PAL\"]\n",
    "\n",
    "#Merge data\n",
    "merged_data_palm = pd.merge(election_palm,shapefiles_palm,on=['Pct_std'],how='outer',indicator=True)\n",
    "palm_elections_only = merged_data_palm[merged_data_palm[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "palm_shapefile_only = merged_data_palm[merged_data_palm[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "palm_both = merged_data_palm[merged_data_palm[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "#Print diffrences\n",
    "print(\"There are \" + str(palm_elections_only.count()) + \" precincts that only appear in the election results\")\n",
    "print(\"There are \" + str(palm_shapefile_only.count()) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(palm_both.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 precincts that only appear in the election results\n",
      "There are 43 precincts that only appear in the shapefile\n",
      "There are 110 precincts that were matched between the two files\n"
     ]
    }
   ],
   "source": [
    "#Take a look\n",
    "#print(shapefiles_pasco.head())\n",
    "\n",
    "#Seems like \"Precinct\" is the right column to use and that it is a unique value\n",
    "#print(shapefiles_pasco[\"Precinct\"].value_counts())\n",
    "\n",
    "#Edit the precinct column to contain at least 4 character\n",
    "shapefiles_pasco[\"Precinct\"]= shapefiles_pasco[\"Precinct\"].str.zfill(4)\n",
    "\n",
    "#Create the unique identifer column\n",
    "shapefiles_pasco[\"Pct_std\"]=\"PAS\"+shapefiles_pasco[\"Precinct\"]\n",
    "\n",
    "#Filter down the election results\n",
    "election_pasco = pivoted_2018[pivoted_2018[\"County\"]==\"PAS\"]\n",
    "\n",
    "#Merge data\n",
    "merged_data_pasco = pd.merge(election_pasco,shapefiles_pasco,on=['Pct_std'],how='outer',indicator=True)\n",
    "pasco_elections_only = merged_data_pasco[merged_data_pasco[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "pasco_shapefile_only = merged_data_pasco[merged_data_pasco[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "pasco_both = merged_data_pasco[merged_data_pasco[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "#Print diffrences\n",
    "print(\"There are \" + str(pasco_elections_only.count()) + \" precincts that only appear in the election results\")\n",
    "print(\"There are \" + str(pasco_shapefile_only.count()) + \" precincts that only appear in the shapefile\")\n",
    "print(\"There are \" + str(pasco_both.count()) + \" precincts that were matched between the two files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of Election and Precinct Data Matching**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the election results, there are 5,999 rows.\n",
    "\n",
    "Of these 5,999 rows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load VEST File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest_fl = gp.read_file(\"/Users/peterhorton/Documents/Redistricting_Data_Hub/Coding/pdv/vest_fl_2018/fl_2018/fl_2018.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the columns from VEST\n",
    "print(vest_fl.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unavailable_from_county = #Highlands, Lake, Sumter, Osceola, Volusia, Columbia, Duval\n",
    "unavailable_from_state = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at the VEST file\n",
    "print(vest_fl.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check my file w/ VEST's\n",
    "\n",
    "vtds_2018_election = pd.merge(pivoted_2018,vest_fl,on=['Pct_std'],how='outer',indicator=True)\n",
    "fl_official_vtds = vtds_2018_election[vtds_2018_election[\"_merge\"]==\"left_only\"]['Pct_std']\n",
    "vest_vtds = vtds_2018_election[vtds_2018_election[\"_merge\"]==\"right_only\"]['Pct_std']\n",
    "matched_vtds = vtds_2018_election[vtds_2018_election[\"_merge\"]==\"both\"]['Pct_std']\n",
    "\n",
    "print(\"There are \" + str(fl_official_vtds.count()) + \" precincts that only appear in the downloaded file\")\n",
    "print(\"There are \" + str(vest_vtds.count()) + \" precincts that only appear in the vest election file\")\n",
    "print(\"There are \" + str(matched_vtds.count()) + \" precincts that were matched between the two files\")\n",
    "\n",
    "#In case you want to save and look at in a spreadsheet\n",
    "#matched_vtds2 = pd.Series(matched_vtds)\n",
    "#matched_vtds2.to_csv(\"./matched_precincts.csv\")\n",
    "\n",
    "#fl_official_vtds2 = pd.Series(fl_official_vtds)\n",
    "#fl_official_vtds2.to_csv(\"./fl_18_official_precincts.csv\")\n",
    "\n",
    "#vest_vtds2 = pd.Series(vest_vtds)\n",
    "#vest_vtds2.to_csv(\"./vest_18_precincts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_data = vtds_2018_election[vtds_2018_election[\"_merge\"]==\"both\"]\n",
    "print(matched_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if any names don't follow the 3 county code and at least 4-digit precinct formula\n",
    "vest_fl[\"check\"]=vest_fl[\"County\"]+vest_fl[\"Precnct\"].astype(str).str.zfill(4)\n",
    "vest_fl[\"confirm\"]=vest_fl[\"Pct_std\"]==vest_fl[\"check\"]\n",
    "print(vest_fl[vest_fl[\"confirm\"]==False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the above, there are 5 precincts from the VEST file that don't follow the formula\n",
    "election_2018_VTD_changes = {\n",
    "    \"UNI1A & 1B\":\"UNI001A\",\n",
    "    \"UNI2A & 2B\":\"UNI002A\",\n",
    "    \"UNI3A & 3B\":\"UNI003A\",\n",
    "    \"UNI4A & 4C\":\"UNI004A\",\n",
    "    \"UNI5A & 5C\":\"UNI005A\",\n",
    "}\n",
    "\n",
    "pivoted_2018['Pct_std'] = pivoted_2018['Pct_std'].map(election_2018_VTD_changes).fillna(pivoted_2018['Pct_std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precincts that only appear in the VEST file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(vest_vtds.value_counts())\n",
    "\n",
    "#There appear to be 67 'PAL00NP' precincts and 23 others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at the \"PAL00NP\"\n",
    "display.max_columns=True\n",
    "\n",
    "#These all look to be 0\n",
    "display(vest_fl[vest_fl['Pct_std']==\"PAL00NP\"])\n",
    "sum(vest_fl[vest_fl['Pct_std']==\"PAL00NP\"][\"G18GOVDGIL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_precncts = [\"PAL00NP\",\"PASGULF\",\"BRE0000\",\"FLA0998\",\"LEO1201\",\"LEO1213\",\"LEO1231\",\"LEO1304\",\"LEO3402\",\"LEO4111\",\"LEO4115\",\"LEO5113\"]\n",
    "print(vtds_2018_election[(vtds_2018_election[\"_merge\"]==\"right_only\")&(~vtds_2018_election[\"Pct_std\"].isin(empty_precncts))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vtds_2018_election[vtds_2018_election[\"_merge\"]==\"right_only\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_precncts=[\"FLA0099\",\"PAL8001\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precincts that only appear in the FL source file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fl_official_vtds.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vtds_2018_election[vtds_2018_election[\"_merge\"]==\"left_only\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_precncts=[\"FLA0099\",\"PAL8001\"]\n",
    "print(vtds_2018_election[(vtds_2018_election[\"_merge\"]==\"left_only\")&(~vtds_2018_election[\"Pct_std\"].isin(empty_precncts))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEM00EV may need to be parceled out\n",
    "others = {\"CAL0201\":\"CAL201/201C\",\"MON0033\":\"MON0041\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(fl_official_vtds[fl_official_vtds['Pct_std']==\"MON0036\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(vest_fl[vest_fl['Pct_std']==\"MON0006\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.max_columns=True\n",
    "display(vest_fl[vest_fl['Pct_std']==\"PAL00NP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest_fl[vest_fl['Pct_std']==\"PAL00NP\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matched_data[matched_data[\"Pct_std\"]==\"DAD0011\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column List should just be a list of columns to be compared with quantitative values\n",
    "#Validating the various columns found in both\n",
    "\n",
    "def validater(df,column_List):\n",
    "    for i in column_List:\n",
    "        left_Data = i + \"_x\"\n",
    "        right_Data = i + \"_y\"\n",
    "        if(sum(df[left_Data]-df[right_Data]) != 0):\n",
    "            print(\"For \" + i + \" total difference is: \" + str(sum(df[left_Data]-df[right_Data])))\n",
    "        \n",
    "column_List = ['G18A10NO','G18A10YES','G18A11NO','G18A11YES','G18A12NO','G18A12YES','G18A13NO','G18A13YES','G18A01NO','G18A01YES',\n",
    "                      'G18A02NO','G18A02YES', 'G18A03NO','G18A03YES','G18A04NO','G18A04YES','G18A05NO','G18A05YES',\n",
    "                      'G18A06NO', 'G18A06YES','G18A07NO', 'G18A07YES','G18A09NO','G18A09YES',\n",
    "                      'G18ATGRMOO', 'G18ATGOSIS','G18ATGDSHA','G18CFODRIN','G18CFORPAT', 'G18AGRRCAL','G18AGRDFRI', \n",
    "                       'G18GOVRDES','G18GOVONPA','G18GOVDGIL','G18GOVORIC','G18USSDNEL','G18USSRSCO']\n",
    "\n",
    "\n",
    "def validater_row (df, column_List):\n",
    "    matching_rows = 0\n",
    "    different_rows = 0\n",
    "    diff_list=[]\n",
    "    \n",
    "    for j in range(0,len(df.index)):\n",
    "        same = True\n",
    "        for i in column_List:\n",
    "            left_Data = i + \"_x\"\n",
    "            right_Data = i + \"_y\"\n",
    "            if(df.iloc[j][left_Data]-df.iloc[j][right_Data] != 0):\n",
    "                #print(df.iloc[j][\"Pct_std\"])\n",
    "                #print(left_Data)\n",
    "                #print(df.iloc[j][left_Data]-df.iloc[j][right_Data])\n",
    "                #print(\"\")\n",
    "                same = False\n",
    "        if(same != True):\n",
    "            different_rows +=1\n",
    "            diff_list.append(df.iloc[j][\"Pct_std\"])\n",
    "            \n",
    "        else:\n",
    "            matching_rows +=1\n",
    "    print(\"There are \", len(df.index),\" total rows\")\n",
    "    print(different_rows,\" of these rows have differences\")\n",
    "    print(matching_rows,\" of these rows are the same\")\n",
    "    print(diff_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vtds_2018_election[vtds_2018_election[\"_merge\"]==\"both\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DAD counties appear to be off by some ratio\n",
    "validater_row(matched_data,column_List)  \n",
    "\n",
    "#MON and WAS counties appear to be off occassionally by ratios and other times by numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_list = ['MON0008', 'MON0009', 'MON0010', 'MON0011', 'MON0012', 'MON0013', 'MON0014', 'MON0015', 'MON0016', 'MON0017', 'MON0018', 'MON0019', 'MON0020', 'MON0021', 'MON0022', 'MON0023', 'MON0024', 'MON0025', 'MON0028', 'MON0029', 'MON0030', 'MON0031', 'MON0032', 'WAS0011', 'WAS0012']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
